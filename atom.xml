<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Arthur&#39;s Blog</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://blog.yapo.fun/"/>
  <updated>2019-11-11T13:27:54.566Z</updated>
  <id>http://blog.yapo.fun/</id>
  
  <author>
    <name>Arthur</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Pros/Cons of allowing push in Prometheus</title>
    <link href="http://blog.yapo.fun/2019/10/30/prometheus/Pros-Cons-of-allowing-push-in-Prometheus/"/>
    <id>http://blog.yapo.fun/2019/10/30/prometheus/Pros-Cons-of-allowing-push-in-Prometheus/</id>
    <published>2019-10-30T07:38:34.000Z</published>
    <updated>2019-11-11T13:27:54.566Z</updated>
    
    <content type="html"><![CDATA[<p>Pros/Cons of allowing push in Prometheus</p><h1 id="Pros"><a href="#Pros" class="headerlink" title="Pros:"></a>Pros:</h1><ol><li><p>Enables IoT use cases with devices at customer / user sites that really can only push</p><p>  These currently don’t have any other TSDB that has Prometheus-style data model and querying, together with its other benefits</p></li><li>Enables other use cases with difficult firewalling or network segments where the operator is not allowed to deploy a Prometheus server in the same network segment or open up ports</li><li>Enables use cases where people want to bulk-import data from existing systems? (even if we treat Prometheus’s DB as ephemeral, it could be useful in some scenarios for people who just want to use PromQL to work with a given data set, which doesn’t even need to be system-monitoring-related)</li></ol><h1 id="Cons"><a href="#Cons" class="headerlink" title="Cons:"></a>Cons:</h1><ol><li><p>People will abuse it:</p><p> Attempt to push events vs. metrics</p><p> Overuse it even if they could use pull, losing pull benefits:</p><pre><code>automatic upness monitoringEasy HA by running two Prometheus serversFlexible collection from laptop, etc.No need to configure identities into instances</code></pre><p> Harder to handle DoS/abuse scenarios</p></li><li>People would expect push support in all client libraries and exporters if the server supported push. We don’t want that, but then we’d only support push halfway, which might seem odd.</li><li>Push-only use cases can arguably be worked around in many cases (e.g. open a tunnel from the pushing device to some proxy, then let Prometheus pull over that; in other cases, it’s possible to run the Prometheus in the same network segment)</li><li><p>No “up” metric<br> Query execution model is designed around pull</p><p> Becomes worse when we fix #398, will make push un-workable in terms of staleness</p></li><li><p>With push comes bottom-up rather than top-down configuration</p><p> This prevents horizontal monitoring</p></li></ol><p>链接：<a href="https://docs.google.com/document/d/1H47v7WfyKkSLMrR8_iku6u9VB73WrVzBHb2SB6dL9_g/edit#" target="_blank" rel="noopener">https://docs.google.com/document/d/1H47v7WfyKkSLMrR8_iku6u9VB73WrVzBHb2SB6dL9_g/edit#</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;Pros/Cons of allowing push in Prometheus&lt;/p&gt;
&lt;h1 id=&quot;Pros&quot;&gt;&lt;a href=&quot;#Pros&quot; class=&quot;headerlink&quot; title=&quot;Pros:&quot;&gt;&lt;/a&gt;Pros:&lt;/h1&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Ena
      
    
    </summary>
    
    
      <category term="prometheus" scheme="http://blog.yapo.fun/tags/prometheus/"/>
    
      <category term="监控" scheme="http://blog.yapo.fun/tags/%E7%9B%91%E6%8E%A7/"/>
    
  </entry>
  
  <entry>
    <title>go scheduler</title>
    <link href="http://blog.yapo.fun/2019/10/15/golang/go-scheduler/"/>
    <id>http://blog.yapo.fun/2019/10/15/golang/go-scheduler/</id>
    <published>2019-10-15T07:56:51.000Z</published>
    <updated>2019-11-11T13:26:06.033Z</updated>
    
    <content type="html"><![CDATA[<h1 id="MPG"><a href="#MPG" class="headerlink" title="MPG"></a>MPG</h1><p>充分利用多核的优势跑更多的任务。</p><p>M: 系统线程</p><p>P: 调度器的上下文</p><p>G: 任务(go routine)的上下文</p><h1 id="调度过程"><a href="#调度过程" class="headerlink" title="调度过程"></a>调度过程</h1><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">                              balance</span><br><span class="line">go func() --&gt; G --&gt; P|local &lt;=========&gt; global</span><br><span class="line">                    |</span><br><span class="line">                    | 唤醒或者新建</span><br><span class="line">                    |</span><br><span class="line">                    M</span><br><span class="line">                    |</span><br><span class="line">                    |</span><br><span class="line">     execute&lt;----schedule</span><br><span class="line">       |            |</span><br><span class="line">       |            |</span><br><span class="line">      G.fn--------&gt;goexit</span><br></pre></td></tr></table></figure><ol><li>语句go func()创建G</li><li>G存在本地队列或者平衡到全局队列</li><li>新建或者唤醒M</li><li>进入调度循环</li><li>竭力获取G并执行</li><li>执行结束进入下一循环</li></ol><h1 id="details"><a href="#details" class="headerlink" title="details"></a>details</h1><p>返回了新创建的G之后会继续执行用户逻辑层代码。Schedule函数在每个goexit函数里面会调用。</p><p>对于3满足下面三个条件会用调用wakep，wakep会唤醒或者新建M:</p><ol><li>pidle不为空</li><li>非main goroutine</li><li>没有M自旋等待P或者G</li></ol><p>对于5，竭力获取G并执行的过程如下:</p><ol><li>有1/61的概率从全局P队列获取G，如果全局队列有G</li><li>从本地P队列获取</li><li>用findrunnable函数，再次从本地P获取，之后是全局P，网络任务，再就是别的运行中的P|M中steal了，如果再没有就一直等到有为止(block住了)</li></ol><p>对于G.fn:</p><ol><li>如果G.fn包含cgo或者用syscall方式block在IO上，需要将当前的P和M解绑，P可能会被别的M取走</li><li>对于RawSysCall类型的系统调用，则直接等待返回(因为速度快的才采用这种方式)</li></ol><p>goroutine切换的可能时机:go fun()、垃圾回收、系统调用、同步与编排:</p><ol><li>mutex同步导致阻塞</li><li>网络IO</li><li>系统调用(syscall)</li><li>channel阻塞</li><li>被sysmon设置为抢占</li><li>关键字go: 新建gourinte</li><li>gc过程中各种策略导致的调度</li></ol><h1 id="一些常量"><a href="#一些常量" class="headerlink" title="一些常量"></a>一些常量</h1><ol><li>M的最大数量是10000</li><li>最小堆栈是2k</li><li>local P的长度是256，还有一个nextG</li><li>g0默认stack空间是8K</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;MPG&quot;&gt;&lt;a href=&quot;#MPG&quot; class=&quot;headerlink&quot; title=&quot;MPG&quot;&gt;&lt;/a&gt;MPG&lt;/h1&gt;&lt;p&gt;充分利用多核的优势跑更多的任务。&lt;/p&gt;
&lt;p&gt;M: 系统线程&lt;/p&gt;
&lt;p&gt;P: 调度器的上下文&lt;/p&gt;
&lt;p&gt;G: 任务(go 
      
    
    </summary>
    
      <category term="golang" scheme="http://blog.yapo.fun/categories/golang/"/>
    
    
      <category term="golang" scheme="http://blog.yapo.fun/tags/golang/"/>
    
      <category term="scheduler" scheme="http://blog.yapo.fun/tags/scheduler/"/>
    
  </entry>
  
  <entry>
    <title>prometheus exporter golang</title>
    <link href="http://blog.yapo.fun/2019/08/13/prometheus/prometheus-exporter-golang/"/>
    <id>http://blog.yapo.fun/2019/08/13/prometheus/prometheus-exporter-golang/</id>
    <published>2019-08-13T06:00:34.000Z</published>
    <updated>2019-11-11T13:26:06.037Z</updated>
    
    <content type="html"><![CDATA[<h2 id="导出默认指标"><a href="#导出默认指标" class="headerlink" title="导出默认指标"></a>导出默认指标</h2><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line"><span class="string">"flag"</span></span><br><span class="line"><span class="string">"log"</span></span><br><span class="line"><span class="string">"net/http"</span></span><br><span class="line"></span><br><span class="line"><span class="string">"github.com/prometheus/client_golang/prometheus/promhttp"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> addr = flag.String(<span class="string">"listen-address"</span>, <span class="string">":8080"</span>, <span class="string">"The address to listen on for HTTP requests."</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">flag.Parse()</span><br><span class="line">http.Handle(<span class="string">"/metrics"</span>, promhttp.Handler())</span><br><span class="line">log.Fatal(http.ListenAndServe(*addr, <span class="literal">nil</span>))</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>核心代码只有一行:<br><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http.Handle(<span class="string">"/metrics"</span>, promhttp.Handler())</span><br></pre></td></tr></table></figure></p><p><code>promhttp.Handler()</code>返回prometheus client中默认注册的handler,其导出默认的metrics,如go routine的数量等.</p><h2 id="自定义指标"><a href="#自定义指标" class="headerlink" title="自定义指标"></a>自定义指标</h2><p>golang的prometheus client提供了一些方便的接口可以注册到默认的promhttp的handler中.</p><p>指标类型有:</p><ul><li>Counter: 一个单调递增值,重启的时候reset为0,如http请求数量</li><li>Gauge: 一个变化值,可变大变小,如温度</li><li>Histogram: 一个历史值,prometheus服务器端可以通过<a href="https://prometheus.io/docs/prometheus/latest/querying/functions/#histogram_quantile" target="_blank" rel="noopener">histogram_quantile()函数</a>计算percentile</li><li>Summary: 一个历史值,在客户端计算</li></ul><p>通过New函数定义相应的metrics并用Set/Add/Observe等函数设置相应的值,并在访问exporter端口时将指标暴露出去.<br>如:<br><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line"><span class="string">"flag"</span></span><br><span class="line"><span class="string">"log"</span></span><br><span class="line"><span class="string">"math"</span></span><br><span class="line"><span class="string">"math/rand"</span></span><br><span class="line"><span class="string">"net/http"</span></span><br><span class="line"><span class="string">"time"</span></span><br><span class="line"></span><br><span class="line"><span class="string">"github.com/prometheus/client_golang/prometheus"</span></span><br><span class="line"><span class="string">"github.com/prometheus/client_golang/prometheus/promhttp"</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> (</span><br><span class="line">addr              = flag.String(<span class="string">"listen-address"</span>, <span class="string">":8080"</span>, <span class="string">"The address to listen on for HTTP requests."</span>)</span><br><span class="line">uniformDomain     = flag.Float64(<span class="string">"uniform.domain"</span>, <span class="number">0.0002</span>, <span class="string">"The domain for the uniform distribution."</span>)</span><br><span class="line">normDomain        = flag.Float64(<span class="string">"normal.domain"</span>, <span class="number">0.0002</span>, <span class="string">"The domain for the normal distribution."</span>)</span><br><span class="line">normMean          = flag.Float64(<span class="string">"normal.mean"</span>, <span class="number">0.00001</span>, <span class="string">"The mean for the normal distribution."</span>)</span><br><span class="line">oscillationPeriod = flag.Duration(<span class="string">"oscillation-period"</span>, <span class="number">10</span>*time.Minute, <span class="string">"The duration of the rate oscillation period."</span>)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="keyword">var</span> (</span><br><span class="line"><span class="comment">//第一步:创建Summary类型和histogram类型的collector</span></span><br><span class="line">    <span class="comment">//此处为New*Vec形式的,定义的labelkey为service,其labelvalue可以有多个</span></span><br><span class="line">rpcDurations = prometheus.NewSummaryVec(</span><br><span class="line">prometheus.SummaryOpts&#123;</span><br><span class="line">Name:       <span class="string">"rpc_durations_seconds"</span>,</span><br><span class="line">Help:       <span class="string">"RPC latency distributions."</span>,</span><br><span class="line">Objectives: <span class="keyword">map</span>[<span class="keyword">float64</span>]<span class="keyword">float64</span>&#123;<span class="number">0.5</span>: <span class="number">0.05</span>, <span class="number">0.9</span>: <span class="number">0.01</span>, <span class="number">0.99</span>: <span class="number">0.001</span>&#125;,</span><br><span class="line">&#125;,</span><br><span class="line">[]<span class="keyword">string</span>&#123;<span class="string">"service"</span>&#125;,</span><br><span class="line">)</span><br><span class="line">    <span class="comment">//此处为New*形式的此处不带labelkey及labelvalue</span></span><br><span class="line">rpcDurationsHistogram = prometheus.NewHistogram(prometheus.HistogramOpts&#123;</span><br><span class="line">Name:    <span class="string">"rpc_durations_histogram_seconds"</span>,</span><br><span class="line">Help:    <span class="string">"RPC latency distributions."</span>,</span><br><span class="line">Buckets: prometheus.LinearBuckets(*normMean<span class="number">-5</span>**normDomain, <span class="number">.5</span>**normDomain, <span class="number">20</span>),</span><br><span class="line">&#125;)</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">init</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="comment">//第二步:使用默认的注册器注册定义的指标</span></span><br><span class="line">    prometheus.MustRegister(rpcDurations)</span><br><span class="line">prometheus.MustRegister(rpcDurationsHistogram)</span><br><span class="line"><span class="comment">//注册build信息仅适用于支持module的go版本</span></span><br><span class="line">prometheus.MustRegister(prometheus.NewBuildInfoCollector())</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">flag.Parse()</span><br><span class="line"></span><br><span class="line">start := time.Now()</span><br><span class="line"></span><br><span class="line">oscillationFactor := <span class="function"><span class="keyword">func</span><span class="params">()</span> <span class="title">float64</span></span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="number">2</span> + math.Sin(math.Sin(<span class="number">2</span>*math.Pi*<span class="keyword">float64</span>(time.Since(start))/<span class="keyword">float64</span>(*oscillationPeriod)))</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//第三步:创建数据</span></span><br><span class="line"><span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="keyword">for</span> &#123;</span><br><span class="line">v := rand.Float64() * *uniformDomain</span><br><span class="line"><span class="comment">//带*Vec形式的collector需要WithLabelValues函数填写lablevalue</span></span><br><span class="line">            rpcDurations.WithLabelValues(<span class="string">"uniform"</span>).Observe(v)</span><br><span class="line">time.Sleep(time.Duration(<span class="number">100</span>*oscillationFactor()) * time.Millisecond)</span><br><span class="line">&#125;</span><br><span class="line">&#125;()</span><br><span class="line"></span><br><span class="line"><span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="keyword">for</span> &#123;</span><br><span class="line">v := (rand.NormFloat64() * *normDomain) + *normMean</span><br><span class="line">            <span class="comment">//带*Vec形式的collector需要WithLabelValues函数填写lablevalue</span></span><br><span class="line">rpcDurations.WithLabelValues(<span class="string">"normal"</span>).Observe(v)</span><br><span class="line">            <span class="comment">//只有New不带*Vec形式的collector直接设置值</span></span><br><span class="line">rpcDurationsHistogram.Observe(v)</span><br><span class="line">time.Sleep(time.Duration(<span class="number">75</span>*oscillationFactor()) * time.Millisecond)</span><br><span class="line">&#125;</span><br><span class="line">&#125;()</span><br><span class="line"></span><br><span class="line"><span class="keyword">go</span> <span class="function"><span class="keyword">func</span><span class="params">()</span></span> &#123;</span><br><span class="line"><span class="keyword">for</span> &#123;</span><br><span class="line">v := rand.ExpFloat64() / <span class="number">1e6</span></span><br><span class="line">            <span class="comment">//带*Vec形式的collector需要WithLabelValues函数填写lablevalue</span></span><br><span class="line">rpcDurations.WithLabelValues(<span class="string">"exponential"</span>).Observe(v)</span><br><span class="line">time.Sleep(time.Duration(<span class="number">50</span>*oscillationFactor()) * time.Millisecond)</span><br><span class="line">&#125;</span><br><span class="line">&#125;()</span><br><span class="line"></span><br><span class="line"><span class="comment">//第四步:暴露指标接口,第三步和第四步无先后顺序</span></span><br><span class="line">http.Handle(<span class="string">"/metrics"</span>, promhttp.Handler())</span><br><span class="line">log.Fatal(http.ListenAndServe(*addr, <span class="literal">nil</span>))</span><br></pre></td></tr></table></figure></p><p>定义的collector的形式为<code>New[type][Vec]</code>,type指定类型,Vec指定labelkey,指标名字在函数参数中定义.<br><strong>自定义的指标会如果不更新会一直export原来的值,而且通过vec定义的labelvalue也会一直在</strong></p><h2 id="自定义exporter"><a href="#自定义exporter" class="headerlink" title="自定义exporter"></a>自定义exporter</h2><p>如果生成的指标时每次采集时生成且labelvalue是动态的,则需要自定义exporter.</p><p>自定义exporter只需要满足Collector接口即可:<br><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">type</span> Collector <span class="keyword">interface</span> &#123;</span><br><span class="line">Describe(<span class="keyword">chan</span>&lt;- *Desc)</span><br><span class="line">Collect(<span class="keyword">chan</span>&lt;- Metric)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>Describe:将此Collector收集的度量标准的所有可能描述符的超集发送到提供的通道，并在最后一个描述符发送后返回。发送的描述符满足了Desc文档中描述的一致性和唯一性要求。如果同一个收集器发送重复的描述符，则它是有效的。这些重复项被简单地忽略了。但是，两个不同的收集器不得发送重复的描述符。完全不发送描述符将收集器标记为“unchecked”，即在注册时不执行任何检查，并且收集器可以在其Collect方法中产生它认为合适的任何指标。此方法在收集器的整个生命周期中有意识地发送相同的描述符。<strong>它可以同时调用，因此必须以并发安全的方式实现</strong>。如果收集器在执行此方法时遇到错误，则它必须发送无效的描述符（使用NewInvalidDesc创建）以向registry发送错误信号。</p><p>Collect:收集指标时，Prometheus registry会调用Collect。实现通过提供的通道发送每个收集的度量标准，并在最后一个度量标准发送后返回。每个发送的度量标准的描述符是Describe返回的度量标准之一（除非收集器是unchecked的）。<strong>共享相同描述符的返回指标的变量标签值必须不同。此方法可以同时调用，因此必须以并发安全的方式实现。</strong>Block发生的代价是呈现所有已注册指标的总体性能。<strong>理想情况下，Collector实现支持并发读者。</strong></p><ol><li><p>定义指标</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 指标结构体</span></span><br><span class="line"><span class="keyword">type</span> Metrics <span class="keyword">struct</span> &#123;</span><br><span class="line">    metrics <span class="keyword">map</span>[<span class="keyword">string</span>]*prometheus.Desc</span><br><span class="line">    mutex   sync.Mutex</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 函数：newGlobalMetric</span></span><br><span class="line"><span class="comment"> * 功能：创建指标描述符</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">newGlobalMetric</span><span class="params">(namespace <span class="keyword">string</span>, metricName <span class="keyword">string</span>, docString <span class="keyword">string</span>, labels []<span class="keyword">string</span>)</span> *<span class="title">prometheus</span>.<span class="title">Desc</span></span> &#123;</span><br><span class="line">    <span class="keyword">return</span> prometheus.NewDesc(namespace+<span class="string">"_"</span>+metricName, docString, labels, <span class="literal">nil</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 工厂方法：NewMetrics</span></span><br><span class="line"><span class="comment"> * 功能：初始化指标信息，即Metrics结构体</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">NewMetrics</span><span class="params">(namespace <span class="keyword">string</span>)</span> *<span class="title">Metrics</span></span> &#123;</span><br><span class="line">    <span class="keyword">return</span> &amp;Metrics&#123;</span><br><span class="line">        metrics: <span class="keyword">map</span>[<span class="keyword">string</span>]*prometheus.Desc&#123;</span><br><span class="line">            <span class="string">"my_counter_metric"</span>: newGlobalMetric(namespace, <span class="string">"my_counter_metric"</span>, <span class="string">"The description of my_counter_metric"</span>, []<span class="keyword">string</span>&#123;<span class="string">"host"</span>&#125;),</span><br><span class="line">            <span class="string">"my_gauge_metric"</span>: newGlobalMetric(namespace, <span class="string">"my_gauge_metric"</span>,<span class="string">"The description of my_gauge_metric"</span>, []<span class="keyword">string</span>&#123;<span class="string">"host"</span>&#125;),</span><br><span class="line">        &#125;,</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure></li><li><p>注册指标</p><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">metrics := collector.NewMetrics(*metricsNamespace)    <span class="comment">// 创建指标结构体实例</span></span><br><span class="line">registry := prometheus.NewRegistry()</span><br><span class="line">registry.MustRegister(metrics)                        <span class="comment">// 注册指标</span></span><br></pre></td></tr></table></figure></li><li><p>数据采集</p></li></ol><p>数据采集需要实现collector的两个接口：<br><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 接口：Describe</span></span><br><span class="line"><span class="comment"> * 功能：传递结构体中的指标描述符到channel</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Metrics)</span> <span class="title">Describe</span><span class="params">(ch <span class="keyword">chan</span>&lt;- *prometheus.Desc)</span></span> &#123;</span><br><span class="line">    <span class="keyword">for</span> _, m := <span class="keyword">range</span> c.metrics &#123;</span><br><span class="line">        ch &lt;- m</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 接口：Collect</span></span><br><span class="line"><span class="comment"> * 功能：抓取最新的数据，传递给channel</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(c *Metrics)</span> <span class="title">Collect</span><span class="params">(ch <span class="keyword">chan</span>&lt;- prometheus.Metric)</span></span> &#123;</span><br><span class="line">    c.mutex.Lock()  <span class="comment">// 加锁</span></span><br><span class="line">    <span class="keyword">defer</span> c.mutex.Unlock()</span><br><span class="line"></span><br><span class="line">    mockCounterMetricData, mockGaugeMetricData := c.GenerateMockData()</span><br><span class="line">    <span class="keyword">for</span> host, currentValue := <span class="keyword">range</span> mockCounterMetricData &#123;</span><br><span class="line">        ch &lt;-prometheus.MustNewConstMetric(c.metrics[<span class="string">"my_counter_metric"</span>], prometheus.CounterValue, <span class="keyword">float64</span>(currentValue), host)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> host, currentValue := <span class="keyword">range</span> mockGaugeMetricData &#123;</span><br><span class="line">        ch &lt;-prometheus.MustNewConstMetric(c.metrics[<span class="string">"my_gauge_metric"</span>], prometheus.GaugeValue, <span class="keyword">float64</span>(currentValue), host)</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;导出默认指标&quot;&gt;&lt;a href=&quot;#导出默认指标&quot; class=&quot;headerlink&quot; title=&quot;导出默认指标&quot;&gt;&lt;/a&gt;导出默认指标&lt;/h2&gt;&lt;figure class=&quot;highlight golang&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gu
      
    
    </summary>
    
      <category term="监控" scheme="http://blog.yapo.fun/categories/%E7%9B%91%E6%8E%A7/"/>
    
    
      <category term="prometheus" scheme="http://blog.yapo.fun/tags/prometheus/"/>
    
      <category term="监控" scheme="http://blog.yapo.fun/tags/%E7%9B%91%E6%8E%A7/"/>
    
  </entry>
  
  <entry>
    <title>prometheus tsdb deeper and lower(2) - Krasi’s Notes! </title>
    <link href="http://blog.yapo.fun/2019/08/12/prometheus/prometheus-tsdb-deeper-and-lower-2/"/>
    <id>http://blog.yapo.fun/2019/08/12/prometheus/prometheus-tsdb-deeper-and-lower-2/</id>
    <published>2019-08-12T03:31:39.000Z</published>
    <updated>2019-11-11T13:26:06.037Z</updated>
    
    <content type="html"><![CDATA[<p>在写入和读取数据时，它会执行此操作</p><ul><li>磁盘上的持久数据 - 块</li><li>内存缓存称为Head - 批量磁盘写入并减少SSD磨损</li></ul><p>当试图理解执行逻辑时，遵循持久化块读取和写入路径可能更容易入手。</p><p><strong>块(Chunk)</strong> - 是字节格式的序列样本的实际持有者。压缩三角形并按<a href="https://github.com/prometheus/tsdb/blob/def6e5a57439cffe7b44a619c05bce4ac513a63e/head.go#L1207" target="_blank" rel="noopener">120</a>个样本分组，以实现快速解压缩。</p><p><code>memSeries</code>结构是所有<code>memChunks</code>保存到磁盘之前的持有者。</p><p>接口:</p><p><a href="https://github.com/prometheus/tsdb/blob/def6e5a57439cffe7b44a619c05bce4ac513a63e/chunkenc/chunk.go#L43-L49" target="_blank" rel="noopener">https://github.com/prometheus/tsdb/blob/def6e5a57439cffe7b44a619c05bce4ac513a63e/chunkenc/chunk.go#L43-L49</a></p><p>通过XORChunk结构实现:</p><p><a href="https://github.com/prometheus/tsdb/blob/def6e5a57439cffe7b44a619c05bce4ac513a63e/chunkenc/xor.go#L1-L386" target="_blank" rel="noopener">https://github.com/prometheus/tsdb/blob/def6e5a57439cffe7b44a619c05bce4ac513a63e/chunkenc/xor.go#L1-L386</a> </p><p><strong>Series</strong> 为labelName/labelValue对,例如:http_requests=post,http_requests=get</p><p><strong>Samples</strong>为timestamp/value对,例如:t:10,v:1234     t:11,v:1200</p><p><a href="https://github.com/prometheus/tsdb/blob/def6e5a57439cffe7b44a619c05bce4ac513a63e/head.go#L53-L73" target="_blank" rel="noopener"><strong>头(Head)</strong></a>-<br>首先，数据保留在内存中以避免将每个样本写入磁盘，因此这允许对大批样本进行单次写入。保存数据的结构是在<br><code>stripeSeries</code>使用<code>map[uint64]</code>由id索引。<br>每个stripeSeries都有自己的互斥锁，以减少锁争用。</p><p>我们通过headAppender将序列/样品添加到Head中。这是将样本分组添加到单个事务中，只有在调用<strong>Commit()</strong>之后才能查询。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">type headAppender struct &#123;</span><br><span class="line">head       *Head</span><br><span class="line">mint, maxt int64</span><br><span class="line">series  []RefSeries</span><br><span class="line">samples []RefSample</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p><code>headAppender</code>实现了Appender接口。</p><ul><li><p>Add(l labels.Labels, t int64, v float64) - 使用标签哈希它检查Head中是否存在（在<code>stripeSeries</code>中）。如果缺少引用它会创建一个新的引用并使用它将新的memSeries添加到head的stripeSeries中。还将标签添加到自己的<code>[]RefSeries</code>切片（为什么????），而不是使用引用调用<code>AddFast</code>. <strong>注:新版本的代码实现是调用AddFast</strong></p></li><li><p>AddFast(ref uint64, t int64, v float64) -  使用ref获取指向时间序列的指针并将样本添加到其<code>[]RefSample</code>切片与引用序列的指针一起使用。通过这种方式在<code>Commit</code>所有t，v对将被添加到由保存的指针引用的相同序列。</p></li><li><p>Commit() - <a href="○https://github.com/prometheus/tsdb/blob/def6e5a57439cffe7b44a619c05bce4ac513a63e/head.go#L526-L531">将所有<code>headAppender</code>序列和样本写入WAL文件</a>。 <a href="○https://github.com/prometheus/tsdb/blob/def6e5a57439cffe7b44a619c05bce4ac513a63e/head.go#L535-L547">遍历所有样本并将它们附加到它们通过保存在它们自己的结构中的系列指针引用的序列中。这也使它们可用于查询</a>。</p></li><li><p>RollBack() - 准备一个空头的appendPool，这样在请求新的appender时它不会分配新的内存。???? 如果我们在调用Rollback后尝试使用现有的appender会发生什么？ **注:调用Rollback之后就不能重用appender了,<a href="https://github.com/prometheus/tsdb/blob/d5b3f0704379a9eaca33b711aa0097f001817fc2/db.go#L89-L90" target="_blank" rel="noopener">详见</a></p></li></ul><p><strong>WAL</strong> - append only文件,用于在发生崩溃时恢复内存中序列,每个WAL段的Head块是256MB，它被截断为重启时写入的内容。再次分区为256MB，你写入了256MB，创建一个新段。</p><p><strong>DB</strong> - 根对象用于设置:</p><ul><li>要使用的目录</li><li>压缩器</li><li>WAL文件</li><li>头部</li><li>读取和写入Meta文件。</li></ul><p><strong>Block</strong> - 持久存储在由单个目录中写入的连续时间序列的非重叠时间窗口限制的磁盘组块上.<strong>注:新版本有实验性质的允许时间窗口重叠的选项</strong></p><p><strong>Compaction(压缩)</strong> - 将块合并在一起以减少查询时间</p><p><strong>Meta文件</strong> - json文件描述块(block)-时间范围，压缩级别等</p><p><strong>Tombstones(墓碑)</strong> - 时间序列设置为在下一次压缩时删除。查询时也会排除这些。</p><p><strong>index(索引)</strong> - 查询数据时使用的索引。压缩数据时会写入索引。postings list - 包含与列表关联的给定标签对的序列引用列表。<a href="https://github.com/prometheus/tsdb/blob/c848349f07c83bd38d5d19faa5ea71c7fd8923ea/index/postings.go#L39" target="_blank" rel="noopener">map[labels.Label][]uint64</a>  -  foo，bar  -  1,3,12,14  - 这意味着带有值bar的标签foo与ID 1,3 ……关联 - 这被用作引用表来获取我们需要的序列。<br>符号 -  ??????????</p><p>非常好的高级概述索引，块，墓碑文件格式:<a href="https://github.com/prometheus/tsdb/tree/master/docs/format" target="_blank" rel="noopener">https://github.com/prometheus/tsdb/tree/master/docs/format</a></p><h1 id="Opening-the-DB-tsdb-Open"><a href="#Opening-the-DB-tsdb-Open" class="headerlink" title="Opening the DB - tsdb.Open"></a>Opening the DB - tsdb.Open</h1><p>选择时间序列：</p><p>创建一个查询器对象，以便能够在1,1000个时间范围内选择数据</p><p><code>querier, err := db.Querier(1, 1000)</code> - 读取所有块（包括头部）的元信息，并返回给定时间范围内每个块的块查询器。</p><p>现在我们需要一些过滤</p><p><code>matcher:=labels.NewEqualMatcher(&quot;foo&quot;, &quot;bar&quot;)</code> - 过滤结果的Matcher接口。</p><p>现在我们可以使用此匹配器运行Select<br><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">querier.Select(matcher)</span><br></pre></td></tr></table></figure></p><p>首先，我们遍历时间范围内所有Block的所有Postings，以找出那些块包含这些Matchers的时间序列。<br><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Head <span class="keyword">struct</span> &#123;</span><br><span class="line"><span class="comment">// All series addressable by their ID or hash.</span></span><br><span class="line">series *stripeSeries - prealocated arrays with locks , partitioned by hash </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>通过headAppender向Head添加序列.<br>headAppender用于一个包含一下内容的切片:<br><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[]RefSeries </span><br><span class="line">Ref    <span class="keyword">uint64</span></span><br><span class="line">Labels labels.Labels</span><br><span class="line">[]RefSample</span><br><span class="line">Ref <span class="keyword">uint64</span></span><br><span class="line">T  <span class="keyword">int64</span></span><br><span class="line">V  <span class="keyword">float64</span></span><br><span class="line">series *memSeries <span class="keyword">struct</span> &#123;</span><br><span class="line">ref          <span class="keyword">uint64</span></span><br><span class="line">lset         labels.Labels</span><br><span class="line">chunks       []*memChunk</span><br><span class="line">chunkRange   <span class="keyword">int64</span></span><br><span class="line">firstChunkID <span class="keyword">int</span></span><br><span class="line">nextAt    <span class="keyword">int64</span> <span class="comment">// timestamp at which to cut the next chunk.</span></span><br><span class="line">lastValue <span class="keyword">float64</span></span><br><span class="line">app chunkenc.Appender <span class="comment">// Current appender for the chunk.</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p><code>headAppender.Add</code>  - 仅获取或创建Series（而不是样本）.通过标签哈希检查Head.stripeSeries中是否存在Series. 如果不存在则生成新的id并通过<code>head.stripeSeries.getOrSet()</code>将新的memSeries添加到全局缓存中.如果创建了新的<code>memSeries</code>，<code>headAppender</code>还会向<code>headAppender.[]RefSeries</code>添加新元素。</p><p>接下来是调用<code>headAppender.AddFast</code>来添加样本。</p><p><code>headAppender.AddFast</code>  - 获取缓存序列，进行一些时间检查以确保样本在<code>headAppender</code>时间范围内，并将样本添加到<code>headAppender.[]RefSample</code>及其引用和指向该序列的指针。（?????如果我们有引用，它为什么要添加完整系列？）</p><p><code>headAppender.Commit()</code> - 将所有<code>[]RefSample</code>和<code>[]RefSeries</code>写入WAL（因此我们不会在发生崩溃时将其丢失），而不是遍历所有<code>[]RefSample</code>并将T和V样本值附加到调用<code>RefSample.series.append(T，V)</code>的序列指针。这开始填充chunk并将每个块中的每120个样本分组。</p><p><strong>Head -&gt; HeadAppender</strong></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;在写入和读取数据时，它会执行此操作&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;磁盘上的持久数据 - 块&lt;/li&gt;
&lt;li&gt;内存缓存称为Head - 批量磁盘写入并减少SSD磨损&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;当试图理解执行逻辑时，遵循持久化块读取和写入路径可能更容易入手。&lt;/p&gt;
&lt;p&gt;&lt;s
      
    
    </summary>
    
      <category term="监控" scheme="http://blog.yapo.fun/categories/%E7%9B%91%E6%8E%A7/"/>
    
    
      <category term="prometheus" scheme="http://blog.yapo.fun/tags/prometheus/"/>
    
      <category term="监控" scheme="http://blog.yapo.fun/tags/%E7%9B%91%E6%8E%A7/"/>
    
  </entry>
  
  <entry>
    <title>prometheus tsdb deeper and lower (1)</title>
    <link href="http://blog.yapo.fun/2019/08/09/prometheus/prometheus-tsdb/"/>
    <id>http://blog.yapo.fun/2019/08/09/prometheus/prometheus-tsdb/</id>
    <published>2019-08-09T05:58:30.000Z</published>
    <updated>2019-11-11T13:26:06.037Z</updated>
    
    <content type="html"><![CDATA[<p>这个<a href="https://fabxc.org/tsdb/" target="_blank" rel="noopener">博客</a>和这个<a href="https://www.youtube.com/watch?v=b_pEevMAC3I" target="_blank" rel="noopener">talk</a>将为您提供有关TSDB如何工作的高级概念，但对于那些想要了解的人来说，这将是一篇较低级别的详细博文。这将有助于人们更好地理解内部结构，并可能成为那些希望做出贡献的人的起点。</p><h1 id="基础"><a href="#基础" class="headerlink" title="基础"></a>基础</h1><p>TSDB是一个数据库。它存储时间序列数据。现在什么是时间序列？时间序列是一系列样本，其中每个样本都是时间戳和值。即一个时间序列是[（t0，v0），（t1 v1），（t2，v2）……]</p><p>现在几乎每个地方都存在时间序列，例如，Austin的天气就是一个例子：<br>[（2017年12月5日下午1点，22点），（2017年12月6日下午1点，6点），（2017年12月7日，-1）….]，除了tsdb采用毫秒精度时间戳和只有float64值。但是我们如何表示或命名时间序列？我们用一组(labelname=labelvalue)表示每个时间序列。例如，Austin的天气可以表示为{name=weather,place=austin,unit=celsius}。</p><p>现在我们需要存储数百万个序列的数据，每个序列都有数百万个样本。然后我们需要能够查询数据。查询现在是二维的，即我们不仅选择时间序列来检索样本数据，还选择时间范围来选择数据。指定时间范围很容易，它只是说从t=t0到t=t1</p><p>现在，在选择时间序列时，我们的数据模型非常容易。我们只需指定labelname-labelvalue约束。例如，要选择<strong>所有</strong>天气时间序列，我们只需使用{name=weather}进行查询。要为Austin选择天气，您只需查询：{name=weather,place=austin}。但约束不仅仅是一个简单的等于约束，我们也有不等于和正则表达式。例如，为Austin以外的每个城市选择天气数据只是:{name=weather,place!=austin}。对于高级用例，我们可以使用类似{name=weather,place=~au.*}的内容，其中=~这里代表正则表达式约束，以选择以”au”开头的所有城市的天气数据。</p><h1 id="高级视图"><a href="#高级视图" class="headerlink" title="高级视图"></a>高级视图</h1><p>现在我们知道了数据和查询的是怎样的，让我们看看tsdb的结构以及它是如何实现的。现在我们有很多数据和很多序列，我们需要存储数据然后有一个索引来帮助我们查询存储的数据。</p><h2 id="数据存储格式"><a href="#数据存储格式" class="headerlink" title="数据存储格式"></a>数据存储格式</h2><p>每个序列的数据都是单独存储的，我们需要存储大量数据。样本是时间戳和值，如果我们有8字节时间戳和8字节值，则每个样本有16个字节。如果我们有500万活跃时间序列，摄入时间为30秒，我们每秒会摄取166K样本，如果我们想将这些数据存储1个月，我们需要7TB的存储空间，如果我们愿意的话存储6个月的数据，然后它会爆炸到42TB，这是一个很大的空间。我们做了一些很好的压缩，使得处理大量数据成为可能。</p><p>这种压缩来自<a href="gorilla paper">Facebook的gorilla论文</a>。我们分别压缩时间戳和值。我们使用Prometheus定期搜索数据的属性。</p><p>现在从压缩我们可以看到，要访问第n个样本，您需要知道第n个样本，依此类推，直到第一个样本。现在你不想解压缩潜在的数十万个值来访问最后一个样本，或者中间的一些样本。因此，我们将数据分块，即将大约120个样本存储(chunk)在一起，并标记这120个样本的开始和结束时间。如果我们需要在特定时间戳访问该值，我们将找到该序列的相关块(chunk)并开始解码。</p><p>现在，实际数据存储在大块文件中，其中每个块(chunk)彼此相邻放置，块的开始的偏移量存储在索引中。</p><h2 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h2><p>现在，当我们累积数据时，每个序列最终会有几个块。<a href="https://github.com/prometheus/tsdb/blob/master/docs/format/index.md" target="_blank" rel="noopener">索引</a>需要帮助我们回答查询，这有助于将labelvalue-labelname匹配器约束转换为具有所有块(chunk)的序列。我们为每个系列分配增量序列ID(seriesID)，然后为每个（lname，lvalue）对构建一个排序<a href="https://github.com/prometheus/tsdb/blob/master/docs/format/index.md" target="_blank" rel="noopener">posting list</a>。即，我们将所有具有该(lname，lvalue)对的序列存储在其labelset中。例如：</p><p>name = weather 10,16,20,22,30,35,50,60,75,100,110,120<br>city = austin 10,12,20,25,50,108,120</p><p>现在，当我们想要回答查询{name=weather,city=austin}时，我们只需要获取<a href="two series">两个序列</a>并获得<a href="https://github.com/prometheus/tsdb/blob/07ef80820ef1250db82f9544f3fcf7f0f63ccee0/querier.go" target="_blank" rel="noopener">id的交集</a>，这应该为我们提供满足查询的所有序列。这里我们基本上采用了所有匹配”name = weather”的序列，并将那些与”city=austin”匹配的序列相交。虽然我们可以回答简单的相等查询，但我们将无法回答正则表达式和不等于查询。</p><p>为此，我们为每个labelname<a href="https://github.com/prometheus/tsdb/blob/07ef80820ef1250db82f9544f3fcf7f0f63ccee0/querier.go" target="_blank" rel="noopener">存储所有可能的labelvalue</a>：</p><p>city: [austin, auckland, hyderabad, berlin, munich…]<br>name: [temp, weather, humidity, … ]</p><p>当我们得到一个正则表达式查询时，我们查看哪个值匹配正则表达式，查询然后检索该posting list。即。如果我们有austin, auckland, pittsburgh，如果我们有正则表达式查询”au.<em>“，我们将检查哪个标签值匹配”au.</em>“，在这种情况下austin和auckland，并获得城市的发布列表city=austin, city=auckland。然后我们将使用seriesID的并集来获得与正则表达式匹配器匹配的seriesID。</p><p>现在我们已经有了相关的序列，我们需要找到该序列的相关块。在索引本身，我们还存储了seriesID-&gt;[chunk1，chunk2，chunk3 ……]映射，其中我们将开始时间，结束时间和偏移量存储到块文件中块的开头。</p><p>现在你可以看到，一旦我们得到一个查询，我们从匹配器中找到相关的序列，然后在指定的时间范围内找到所有重叠的块(chunk)并解码它们以获得所有相关的值。</p><p>—————— INCOMPLETE —————–</p><h2 id="多个DB"><a href="#多个DB" class="headerlink" title="多个DB"></a>多个DB</h2><p>现在，序列不是恒定的。他们来去匆匆。有些序列只收到几个小时样本，而我们的数据库可以保存数月的数据。现在，如果我们有一个包含所有序列的大型索引，那么如果我们请求2小时的数据，可能只有100K序列在那个时间段内收到了样本，但我们在整个过程中收到样本时间范围内可能有超过5M的序列。这意味着每个查询，即使在1分钟的时间范围内，也会触及所有序列的巨大膨胀指数，这只会随着数据库变大而变得更糟。</p><p>这是Prometheus之前数据库的问题之一。实际上要解决这个问题(此处文档不完善,需要插入sharding的逻辑和好处)</p><h1 id="internals"><a href="#internals" class="headerlink" title="internals"></a>internals</h1><p>现在让我们看看应用程序如何使用tsdb并查看内部结构。该应用程序使用<a href="https://gist.github.com/Gouthamve/752a312efe40268a8d4ef844c95ed0d2" target="_blank" rel="noopener"><code>* tsdb.DB</code>对象</a>.</p><p>这里我们创建一个db，传递一个文件夹和选项。选项基本上是说，将<a href="https://en.wikipedia.org/wiki/Write-ahead_logging" target="_blank" rel="noopener">预写日志记录</a>到磁盘，丢弃超过15天的数据，并将大小为15分钟的块，然后压缩到1小时，然后压缩到4小时的最大时间范围。</p><p>现在，该应用程序使用一个appender：<a href="https://godoc.org/github.com/prometheus/tsdb#Appender" target="_blank" rel="noopener">tsdb.Appender</a> 。当我们执行<a href="https://github.com/prometheus/tsdb/blob/07ef80820ef1250db82f9544f3fcf7f0f63ccee0/head.go#L480-L493" target="_blank" rel="noopener">app.Add(serries,sample)</a>时，我们检查数据库中是否存在序列，如果序列存在,则获取其ref，然后在appender中对ref添加样本。如果序列不存在，请在数据库中创建系列，然后将其添加到新的ref。<a href="https://github.com/prometheus/tsdb/blob/07ef80820ef1250db82f9544f3fcf7f0f63ccee0/head.go#L878-L891" target="_blank" rel="noopener">CODE</a></p><p>当我们调用<a href="https://github.com/prometheus/tsdb/blob/07ef80820ef1250db82f9544f3fcf7f0f63ccee0/head.go#L524-L563" target="_blank" rel="noopener">Commit()</a>时，我们继续将数据添加到 * head中的实际序列中，使其可用于查询而不仅仅是在appender中。</p><p>注意：这不是孤立的，查询有时可以从提交中读取部分数据。</p><p><strong>注: 这个问题已经有PR解决了<a href="https://github.com/prometheus/tsdb/pull/306" target="_blank" rel="noopener">https://github.com/prometheus/tsdb/pull/306</a></strong></p><p>————– INCOMPLETE, SKIP ———————</p><h2 id="追加路径"><a href="#追加路径" class="headerlink" title="追加路径"></a>追加路径</h2><p>现在我们看到数据被附加到<code>db.head</code>内存块，我们在上面解释的在内存中维护的可变块。它有序列索引LIKE THIS和实际系列存储在这里。</p><p>现在当我们调用<code>Appender()</code>时，我们创建了headAppender结构，它存储了该事务的所有数据。现在，当我们调用Add()时，我们在这里添加数据，我们在这里创建序列。</p><p>当调用commit时，我们继续将序列附加到引用的序列中。</p><hr><h2 id="压缩路径"><a href="#压缩路径" class="headerlink" title="压缩路径"></a>压缩路径</h2><p>现在，我们需要定期将头块刷新到磁盘以减少内存使用量。我们根据时间范围而不是头块大小进行刷新。这个持续时间是我们在选项中传递的最小块大小，在这种情况下，它是15分钟。</p><p>现在每个<a href="https://github.com/prometheus/tsdb/blob/07ef80820ef1250db82f9544f3fcf7f0f63ccee0/db.go#L331-L402" target="_blank" rel="noopener">压缩循环</a>，<a href="https://github.com/prometheus/tsdb/blob/07ef80820ef1250db82f9544f3fcf7f0f63ccee0/db.go#L250" target="_blank" rel="noopener">每1分钟</a>，我们检查一下<a href="https://github.com/prometheus/tsdb/blob/07ef80820ef1250db82f9544f3fcf7f0f63ccee0/db.go#L347-L351" target="_blank" rel="noopener">头块是否有超过22.5分钟（1.5 * 15分钟）的未刷入数据</a>。这个0.5的缓冲区是为了确保我们可以附加旧的时间戳。<a href="https://github.com/prometheus/tsdb/blob/07ef80820ef1250db82f9544f3fcf7f0f63ccee0/db.go#L352-L362" target="_blank" rel="noopener">如果确实存在22.5分钟的数据，我们将最后15分钟的数据作为新块刷新到磁盘</a>并<a href="https://github.com/prometheus/tsdb/blob/def6e5a57439cffe7b44a619c05bce4ac513a63e/db.go#L556" target="_blank" rel="noopener">从内存中删除数据</a>。</p><p>现在我们还谈到了随着时间的增长，我们如何将较小的块压缩成更大的块。如果headblock足够小以至于不能刷入，我们会看是否有任何需要压缩的块。如果有，我们收集它们，<a href="https://github.com/prometheus/tsdb/blob/07ef80820ef1250db82f9544f3fcf7f0f63ccee0/db.go#L389-L391" target="_blank" rel="noopener">然后将它们压缩在一起</a>。</p><h2 id="请求路径"><a href="#请求路径" class="headerlink" title="请求路径"></a>请求路径</h2><p>现在让我们看看查询是如何工作的。 这稍微复杂一些。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">q, err := db.Querier(1, 1000)</span><br><span class="line"></span><br><span class="line">rem, err := labels.NewRegexpMatcher(&quot;a&quot;, &quot;b.*&quot;)</span><br><span class="line">seriesSet, err := q.Select(rem)</span><br><span class="line"></span><br><span class="line">for seriesSet.Next() &#123;</span><br><span class="line">// Get each Series</span><br><span class="line">s := seriesSet.At()</span><br><span class="line">fmt.Println(&quot;Labels:&quot;, s.Labels())</span><br><span class="line">fmt.Println(&quot;Data:&quot;)</span><br><span class="line">it := s.Iterator()</span><br><span class="line">for it.Next() &#123;</span><br><span class="line">ts, v := it.At()</span><br><span class="line">fmt.Println(&quot;ts =&quot;, ts, &quot;v =&quot;, v)</span><br><span class="line">&#125;</span><br><span class="line">if err := it.Err(); err != nil &#123;</span><br><span class="line">panic(err)</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>我们首先获得最小时间和最大时间的查询器，然后根据匹配器选择序列。 对于每个序列，我们检索标签和样本。</p><p>现在当<a href="https://github.com/prometheus/tsdb/blob/master/db.go#L634-L666" target="_blank" rel="noopener">db.Querier(1,1000)</a>时，我们将选取传递时间范围数据的所有存储块。当调用q.Select时，我们继续并获取<a href="https://github.com/prometheus/tsdb/blob/07ef80820ef1250db82f9544f3fcf7f0f63ccee0/querier.go#L211" target="_blank" rel="noopener">每个匹配器的postings list</a>并将<a href="https://github.com/prometheus/tsdb/blob/07ef80820ef1250db82f9544f3fcf7f0f63ccee0/querier.go#L217" target="_blank" rel="noopener">它们相交</a>。</p><p>现在，我们有了seriesID，我们在这些seriesID上<a href="https://github.com/prometheus/tsdb/blob/07ef80820ef1250db82f9544f3fcf7f0f63ccee0/querier.go#L156-L170" target="_blank" rel="noopener">返回迭代器</a>。现在，每当调用seriesSet.Next()时，我们首先获取该seriesID的<a href="https://github.com/prometheus/tsdb/blob/07ef80820ef1250db82f9544f3fcf7f0f63ccee0/querier.go#L508-L516" target="_blank" rel="noopener">labelset</a>和chunk元数据，然后从<a href="https://github.com/prometheus/tsdb/blob/07ef80820ef1250db82f9544f3fcf7f0f63ccee0/querier.go#L588" target="_blank" rel="noopener">实际的chunk文件中查找块</a>。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;这个&lt;a href=&quot;https://fabxc.org/tsdb/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;博客&lt;/a&gt;和这个&lt;a href=&quot;https://www.youtube.com/watch?v=b_pEevMAC3I&quot; target=
      
    
    </summary>
    
      <category term="监控" scheme="http://blog.yapo.fun/categories/%E7%9B%91%E6%8E%A7/"/>
    
    
      <category term="prometheus" scheme="http://blog.yapo.fun/tags/prometheus/"/>
    
      <category term="监控" scheme="http://blog.yapo.fun/tags/%E7%9B%91%E6%8E%A7/"/>
    
  </entry>
  
  <entry>
    <title>golang time 序列化反序列化</title>
    <link href="http://blog.yapo.fun/2019/07/18/golang/golang-time-json/"/>
    <id>http://blog.yapo.fun/2019/07/18/golang/golang-time-json/</id>
    <published>2019-07-18T14:24:01.000Z</published>
    <updated>2019-11-11T13:26:06.033Z</updated>
    
    <content type="html"><![CDATA[<p>golang中反序列化字符串推荐用time.RFC3339<br><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">RFC3339     = <span class="string">"2006-01-02T15:04:05Z07:00"</span></span><br><span class="line">RFC3339Nano = <span class="string">"2006-01-02T15:04:05.999999999Z07:00"</span></span><br></pre></td></tr></table></figure></p><p>golang根据传递的字符串自动反序列化成time.Time类型并包含时区信息,序列化时根据时区进行序列化显示.<br><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> main</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> (</span><br><span class="line"><span class="string">"encoding/json"</span></span><br><span class="line"><span class="string">"fmt"</span></span><br><span class="line"><span class="string">"time"</span></span><br><span class="line">)</span><br><span class="line"><span class="comment">//代码在东八区的机器上运行</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="title">main</span><span class="params">()</span></span> &#123;</span><br><span class="line">    tnow:=time.Now()</span><br><span class="line">    ret, err := json.Marshal(tnow)</span><br><span class="line">    fmt.Println(<span class="keyword">string</span>(ret), err)</span><br><span class="line">    <span class="comment">//输出当前东八区时间</span></span><br><span class="line">    <span class="comment">// "2019-07-18T22:53:00.987584125+08:00" &lt;nil&gt;</span></span><br><span class="line">   </span><br><span class="line">    t, _ := time.Parse(time.RFC3339, <span class="string">"2019-07-18T13:59:33.342880414Z"</span>)</span><br><span class="line">ret, err = json.Marshal(t)</span><br><span class="line">    fmt.Println(<span class="keyword">string</span>(ret), err)</span><br><span class="line">    <span class="comment">// 输出内容如下,和解析内容一致</span></span><br><span class="line">    <span class="comment">// "2019-07-18T13:59:33.342880414Z" &lt;nil&gt;</span></span><br><span class="line">    fmt.Println(<span class="string">"---------------------"</span>)</span><br><span class="line">    </span><br><span class="line">    t, _ = time.Parse(time.RFC3339, <span class="string">"2019-07-18T21:38:23.712986149+08:00"</span>)</span><br><span class="line">ret, err = json.Marshal(t)</span><br><span class="line">    fmt.Println(<span class="keyword">string</span>(ret), err)</span><br><span class="line">    <span class="comment">// 输出内容如下,和解析内容一致</span></span><br><span class="line">    <span class="comment">// "2019-07-18T21:38:23.712986149+08:00" &lt;nil&gt;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>在docker上运行的机器默认是UTC时间,而我们在东八区北京时间.若有一个运行docker的进程用time.Now()(返回的UTC时间),则格式实际为time.RFC3339的UTC时间,而在docker之外运行的东八区的进行反序列化之后,进行运算,最后序列化输出的还是time.RFC3339格式的UTC时间.若接收方为其它语言如python编写的则需要解析RFC3339格式,否则否则容易出现时区误差.</p><h2 id="MarshalJSON-UnmarshalJSON"><a href="#MarshalJSON-UnmarshalJSON" class="headerlink" title="MarshalJSON/UnmarshalJSON"></a>MarshalJSON/UnmarshalJSON</h2><p>序列化时默认使用RFC3339Nano格式,但不是UTC的会按时区显示.<br><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// MarshalJSON implements the json.Marshaler interface.</span></span><br><span class="line"><span class="comment">// The time is a quoted string in RFC 3339 format, with sub-second precision added if present.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(t Time)</span> <span class="title">MarshalJSON</span><span class="params">()</span> <span class="params">([]<span class="keyword">byte</span>, error)</span></span> &#123;</span><br><span class="line"><span class="keyword">if</span> y := t.Year(); y &lt; <span class="number">0</span> || y &gt;= <span class="number">10000</span> &#123;</span><br><span class="line"><span class="comment">// RFC 3339 is clear that years are 4 digits exactly.</span></span><br><span class="line"><span class="comment">// See golang.org/issue/4556#c15 for more discussion.</span></span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span>, errors.New(<span class="string">"Time.MarshalJSON: year outside of range [0,9999]"</span>)</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">b := <span class="built_in">make</span>([]<span class="keyword">byte</span>, <span class="number">0</span>, <span class="built_in">len</span>(RFC3339Nano)+<span class="number">2</span>)</span><br><span class="line">b = <span class="built_in">append</span>(b, <span class="string">'"'</span>)</span><br><span class="line">b = t.AppendFormat(b, RFC3339Nano)</span><br><span class="line">b = <span class="built_in">append</span>(b, <span class="string">'"'</span>)</span><br><span class="line"><span class="keyword">return</span> b, <span class="literal">nil</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>UnmarshalJSON默认使用RFC3339格式解析,但非UTC的按时区设置时区<br><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// UnmarshalJSON implements the json.Unmarshaler interface.</span></span><br><span class="line"><span class="comment">// The time is expected to be a quoted string in RFC 3339 format.</span></span><br><span class="line"><span class="function"><span class="keyword">func</span> <span class="params">(t *Time)</span> <span class="title">UnmarshalJSON</span><span class="params">(data []<span class="keyword">byte</span>)</span> <span class="title">error</span></span> &#123;</span><br><span class="line"><span class="comment">// Ignore null, like in the main JSON package.</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">string</span>(data) == <span class="string">"null"</span> &#123;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// Fractional seconds are handled implicitly by Parse.</span></span><br><span class="line"><span class="keyword">var</span> err error</span><br><span class="line">*t, err = Parse(<span class="string">`"`</span>+RFC3339+<span class="string">`"`</span>, <span class="keyword">string</span>(data))</span><br><span class="line"><span class="keyword">return</span> err</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="python-rfc3339库"><a href="#python-rfc3339库" class="headerlink" title="python rfc3339库"></a>python rfc3339库</h2><p>安装tonyg-rfc3339:<br><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install tonyg-rfc3339</span><br></pre></td></tr></table></figure></p><p>测试代码如下,时间差相同:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> rfc3339,datetime</span><br><span class="line">dt = rfc3339.parse_datetime(<span class="string">"2019-07-18T21:38:23.712986149+08:00"</span>)</span><br><span class="line">now = datetime.datetime.now(dt.tzinfo)</span><br><span class="line">print(now -dt)</span><br><span class="line"><span class="comment">#输出:2:09:36.500622</span></span><br><span class="line"></span><br><span class="line">dt = rfc3339.parse_datetime(<span class="string">"2019-07-18T13:38:23.712986149Z"</span>)</span><br><span class="line">now = datetime.datetime.now(dt.tzinfo)</span><br><span class="line">print(now -dt)</span><br><span class="line"><span class="comment"># 输出: 2:09:36.500667</span></span><br></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;golang中反序列化字符串推荐用time.RFC3339&lt;br&gt;&lt;figure class=&quot;highlight golang&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span
      
    
    </summary>
    
      <category term="golang" scheme="http://blog.yapo.fun/categories/golang/"/>
    
    
      <category term="golang" scheme="http://blog.yapo.fun/tags/golang/"/>
    
      <category term="function" scheme="http://blog.yapo.fun/tags/function/"/>
    
  </entry>
  
  <entry>
    <title>thanos弃用gossip采用文件发现服务(file discovery service)的原因</title>
    <link href="http://blog.yapo.fun/2019/06/28/thanos/thanos-gossip/"/>
    <id>http://blog.yapo.fun/2019/06/28/thanos/thanos-gossip/</id>
    <published>2019-06-28T15:49:50.000Z</published>
    <updated>2019-11-11T13:26:06.037Z</updated>
    
    <content type="html"><![CDATA[<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ol><li>做不了负载均衡(可直接访问peer的IP地址)</li><li>私有IP地址推断有可能会出错</li><li>没必要让每个peer都知道对方的存在,Thanos query/rule知道store就可以了</li><li>作者觉得维护麻烦，省了一件事</li></ol><h2 id="详细信息"><a href="#详细信息" class="headerlink" title="详细信息"></a>详细信息</h2><p><a href="https://thanos.io/proposals/201809_gossip-removal.md/" target="_blank" rel="noopener">官网</a></p><ul><li>Gossip has been proven to be extremely confusing for the new users. Peer logic and really confusing <code>cluster.advertise-address</code> that was sometimes able to magically deduce private IP address (and sometimes not!) were leading to lots of questions and issues. Something that was made for quick ramp-up into Thanos (“just click the button and it auto-joins everything”) created lots of confusion and made it harder to experiment. </li></ul><p><strong> Gossip给新用户带来困扰。Peer逻辑和让人困扰的<code>cluster.advertise-address</code>带来很多问题。<code>cluster.advertise-address</code>有时候能神奇的推断出私有IP地址，有时候不可以！Gossip这种自动加入的特性使其难以进行试验。</strong></p><ul><li>Auto-join logic has its price. All peers connected were aware of each other. All were included in metadata propagation. Membership project community made an awesome job to optimize N^N communication (all-to-all), but nevertheless, it is something that is totally unnecessary to Thanos. And it led to wrong assumptions that e.g sidecar needs to be aware of another sidecar etc. Thanos Querier is the only component that requires to be aware of other StoreAPIs. It is clear that all-to-all communication is neither necessary nor educative. </li></ul><p>自动加入逻辑是有代价的。<strong>所有的用户都相互知道对方的存在。所有信息都在包含在元信息传播中。</strong> 成员关系工程社区对这种<strong>N^N的通信(所有-所有)</strong>的通信做了非常好的优化，然而，有时候这对Thanos来说是完全没必要的。并且导致错误的假设，比如，sidecar需要知道别的sidecar。Thanos Query是为一个一个需要知道其它store API的组件。显然这种所有-所有的通信既没必要也没有可学习的。</p><ul><li>Unless specifically configured (which requires advanced knowledge) Gossip uses mix of TCP and UPD underneath its custom app level protocol. This is a no-go if you use L7 loadbalancers and proxies. </li></ul><p><strong>除非特意配置(需要高级知识)，Gossip在定制的APP层协议下混合使用TCP和UDP。如果你使用7层负载均衡或者代理，这是不可行的。</strong></p><ul><li>Global gossip is really difficult to achieve. BTW, If you know how to setup this, please write a blog about it! (: </li></ul><p>难以实现。</p><ul><li>With the addition of the simplest possible solution to give Thanos Querier knowledge where are StoreAPIs (static –store flag), we needed to implement health check and metadata propagation anyway. In fact, StoreAPI.Info was already there all the time. </li></ul><ul><li>Gossip operates per peer level and there is no way you can abstract multiple peers behind loadbalancer. This hides easy solutions from our eyes, e.g how to make Store Gateway HA. Without gossip, you can just use Kubernetes HA Service or any other loadbalancer. To support Store Gateway HA for gossip we would end up implementing LB logic in Thanos Querier (like proposed here) </li></ul><p><strong>Gossip在对等层运行，没有办法可以抽象多个peer到负载均衡器之后。</strong></p><ul><li>At some point we want to be flexible and allow other discovery mechanisms. Gossip does not work for everyone and static flags are too.. static. (: We need File SD for flexibility anyway. </li></ul><p><strong> 有时候，我们希望一定的灵活性并且允许其它的发现机制。Gossip并不对每个人都有用，static flag又太静态了。。。 </strong></p><ul><li>One thing less to maintain.</li></ul><p><strong> 少维护一件事 </strong></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;总结&quot;&gt;&lt;a href=&quot;#总结&quot; class=&quot;headerlink&quot; title=&quot;总结&quot;&gt;&lt;/a&gt;总结&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;做不了负载均衡(可直接访问peer的IP地址)&lt;/li&gt;
&lt;li&gt;私有IP地址推断有可能会出错&lt;/li&gt;
&lt;li&gt;没必要让每个p
      
    
    </summary>
    
      <category term="监控" scheme="http://blog.yapo.fun/categories/%E7%9B%91%E6%8E%A7/"/>
    
    
      <category term="监控" scheme="http://blog.yapo.fun/tags/%E7%9B%91%E6%8E%A7/"/>
    
      <category term="thanos" scheme="http://blog.yapo.fun/tags/thanos/"/>
    
  </entry>
  
  <entry>
    <title>ubuntu18.04环境配置</title>
    <link href="http://blog.yapo.fun/2019/06/11/ENV/ubuntu%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"/>
    <id>http://blog.yapo.fun/2019/06/11/ENV/ubuntu环境配置/</id>
    <published>2019-06-11T15:37:20.000Z</published>
    <updated>2019-11-11T13:26:06.033Z</updated>
    
    <content type="html"><![CDATA[<h2 id="设置最大打开文件数"><a href="#设置最大打开文件数" class="headerlink" title="设置最大打开文件数"></a>设置最大打开文件数</h2><ol><li><p>图形界面登录: 设置/etc/systemd/user.conf及/etc/systemd/system.conf中的DefaultLimitNOFILE</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DefaultLimitNOFILE=65535</span><br></pre></td></tr></table></figure></li><li><p>非图形界面登录:修改/etc/security/limits.conf或在/etc/security/limits.d目录下新创建一个文件，然后设置</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">* soft nofile 65535</span><br><span class="line">* hard nofile 65535</span><br></pre></td></tr></table></figure></li></ol><p><strong>NB</strong>:设置之后需要重新启动</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;设置最大打开文件数&quot;&gt;&lt;a href=&quot;#设置最大打开文件数&quot; class=&quot;headerlink&quot; title=&quot;设置最大打开文件数&quot;&gt;&lt;/a&gt;设置最大打开文件数&lt;/h2&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;图形界面登录: 设置/etc/systemd/user.conf及
      
    
    </summary>
    
    
      <category term="ENV" scheme="http://blog.yapo.fun/tags/ENV/"/>
    
  </entry>
  
  <entry>
    <title>m3db分片和复制</title>
    <link href="http://blog.yapo.fun/2019/05/16/m3db-sharding-and-replication/"/>
    <id>http://blog.yapo.fun/2019/05/16/m3db-sharding-and-replication/</id>
    <published>2019-05-16T14:57:00.000Z</published>
    <updated>2019-11-11T13:26:06.033Z</updated>
    
    <content type="html"><![CDATA[<h2 id="分片"><a href="#分片" class="headerlink" title="分片"></a>分片</h2><p>时间序列键被散列到一组固定的虚拟分片。然后将虚拟分片分配给物理节点。可以将M3DB配置为使用任何散列函数和配置数量的分片。默认情况下，<a href="https://en.wikipedia.org/wiki/MurmurHash" target="_blank" rel="noopener">murmur3</a>用作散列函数，并配置4096个虚拟分片。</p><h2 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h2><p>分片在整个M3DB堆栈中提供了各种好处：</p><ol><li>它们使得水平扩展更容易，并且可以在集群级别上添加/删除节点而无需停机。</li><li>它们在内存级别提供更细粒度的锁粒度。</li><li>它们通知文件系统组织，属于同一分片的数据将被一起使用/删除，并且可以保存在同一文件中。</li></ol><h2 id="复制-Replication"><a href="#复制-Replication" class="headerlink" title="复制(Replication)"></a>复制(Replication)</h2><p>每个副本的虚拟分片放置逻辑分片，并具有可配置的隔离（区域感知，机架识别等）。例如，当使用机架感知隔离时，定位副本数据的数据中心机架集与定位所有其他副本数据的机架不同。</p><p>复制在写入期间是同步的，并且根据配置的一致性级别将通知客户端关于一致性级别和复制实现的写入是成功还是失败。</p><h2 id="复本-Replica"><a href="#复本-Replica" class="headerlink" title="复本(Replica)"></a>复本(Replica)</h2><p>每个副本都有自己的每个虚拟分片的单个逻辑分片的分配。</p><p>从概念上讲，它可以定义为：<br><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Replica &#123;</span><br><span class="line">  id <span class="keyword">uint32</span></span><br><span class="line">  shards []Shard</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="分片状态"><a href="#分片状态" class="headerlink" title="分片状态"></a>分片状态</h2><p>每个分片在概念上可以定义为：<br><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">Shard &#123;</span><br><span class="line">  id <span class="keyword">uint32</span></span><br><span class="line">  assignments []ShardAssignment</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">ShardAssignment &#123;</span><br><span class="line">  host Host</span><br><span class="line">  state ShardState</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">enum ShardState &#123;</span><br><span class="line">  INITIALIZING,</span><br><span class="line">  AVAILABLE,</span><br><span class="line">  LEAVING</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="分片分配"><a href="#分片分配" class="headerlink" title="分片分配"></a>分片分配</h2><p>分片的分配存储在etcd中。添加，删除或替换节点分片时，会为分配的每个分片分配目标状态。</p><p>要使写入对于给定副本显示为成功，它必须对该分片的所有已分配主机成功。这意味着如果存在给定的分片，其中主机被指定为LEAVING而另一个主机被分配为INITIALIZING，则给定的副本写入这两个主机必须看起来成功返回成功以写入该给定副本。然而，目前只有可用的分片计入一致性，在计算写入成功/错误时将LEAVING和INITIALIZING分片组合在一起的工作尚未完成，参见<a href="https://github.com/m3db/m3/issues/417" target="_blank" rel="noopener">问题417</a>。</p><p>当在INITIALIZING状态中发现分配新分片时，由节点本身自行引导分片，并在完成后通过调用集群管理API将状态转换为AVAILABLE。使用比较并以原子方式设置它将删除仍分配给先前拥有它的节点的LEAVING分片，并将新节点上的分片状态从INITIALIZING状态转换为AVAILABLE。</p><p>节点将不会开始为新分片提供读取，直到变为AVAILABLE，这意味着直到它们为这些分片提供了引导数据。</p><h2 id="群集操作"><a href="#群集操作" class="headerlink" title="群集操作"></a>群集操作</h2><h3 id="节点添加"><a href="#节点添加" class="headerlink" title="节点添加"></a>节点添加</h3><p>将节点添加到群集时，会为其分配分片，从而可以从现有节点中公平地减轻负载。 分配给新节点的分片将变为INITIALIZING，然后节点发现它们需要被引导，并将使用所有可用的副本开始引导数据。 将从现有节点中删除的分片标记为LEAVING。</p><h3 id="节点宕机"><a href="#节点宕机" class="headerlink" title="节点宕机"></a>节点宕机</h3><p>需要明确地从群集中取出节点。 如果节点发生故障并且不可用，则执行读取的客户端将从副本中为该节点拥有的分片范围提供错误。 在此期间，它将依赖来自其他副本的读取来继续不间断的操作。</p><h3 id="节点移除"><a href="#节点移除" class="headerlink" title="节点移除"></a>节点移除</h3><p>删除节点后，它拥有的分片将分配给群集中的现有节点。剩余的服务器发现它们现在拥有INITIALIZING的分片，需要进行自举，并将使用所有可用的副本开始引导数据。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;分片&quot;&gt;&lt;a href=&quot;#分片&quot; class=&quot;headerlink&quot; title=&quot;分片&quot;&gt;&lt;/a&gt;分片&lt;/h2&gt;&lt;p&gt;时间序列键被散列到一组固定的虚拟分片。然后将虚拟分片分配给物理节点。可以将M3DB配置为使用任何散列函数和配置数量的分片。默认情况下，&lt;a 
      
    
    </summary>
    
    
      <category term="m3db" scheme="http://blog.yapo.fun/tags/m3db/"/>
    
      <category term="时间序列数据库" scheme="http://blog.yapo.fun/tags/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>m3db分片和复制</title>
    <link href="http://blog.yapo.fun/2019/05/16/m3/m3db/architecure/m3db-sharding-and-replication/"/>
    <id>http://blog.yapo.fun/2019/05/16/m3/m3db/architecure/m3db-sharding-and-replication/</id>
    <published>2019-05-16T14:57:00.000Z</published>
    <updated>2019-11-11T13:26:06.033Z</updated>
    
    <content type="html"><![CDATA[<h2 id="分片"><a href="#分片" class="headerlink" title="分片"></a>分片</h2><p>时间序列键被散列到一组固定的虚拟分片。然后将虚拟分片分配给物理节点。可以将M3DB配置为使用任何散列函数和配置数量的分片。默认情况下，<a href="https://en.wikipedia.org/wiki/MurmurHash" target="_blank" rel="noopener">murmur3</a>用作散列函数，并配置4096个虚拟分片。</p><h2 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h2><p>分片在整个M3DB堆栈中提供了各种好处：</p><ol><li>它们使得水平扩展更容易，并且可以在集群级别上添加/删除节点而无需停机。</li><li>它们在内存级别提供更细粒度的锁粒度。</li><li>它们通知文件系统组织，属于同一分片的数据将被一起使用/删除，并且可以保存在同一文件中。</li></ol><h2 id="复制-Replication"><a href="#复制-Replication" class="headerlink" title="复制(Replication)"></a>复制(Replication)</h2><p>每个副本的虚拟分片放置逻辑分片，并具有可配置的隔离（区域感知，机架识别等）。例如，当使用机架感知隔离时，定位副本数据的数据中心机架集与定位所有其他副本数据的机架不同。</p><p>复制在写入期间是同步的，并且根据配置的一致性级别将通知客户端关于一致性级别和复制实现的写入是成功还是失败。</p><h2 id="复本-Replica"><a href="#复本-Replica" class="headerlink" title="复本(Replica)"></a>复本(Replica)</h2><p>每个副本都有自己的每个虚拟分片的单个逻辑分片的分配。</p><p>从概念上讲，它可以定义为：<br><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Replica &#123;</span><br><span class="line">  id <span class="keyword">uint32</span></span><br><span class="line">  shards []Shard</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="分片状态"><a href="#分片状态" class="headerlink" title="分片状态"></a>分片状态</h2><p>每个分片在概念上可以定义为：<br><figure class="highlight golang"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">Shard &#123;</span><br><span class="line">  id <span class="keyword">uint32</span></span><br><span class="line">  assignments []ShardAssignment</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">ShardAssignment &#123;</span><br><span class="line">  host Host</span><br><span class="line">  state ShardState</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">enum ShardState &#123;</span><br><span class="line">  INITIALIZING,</span><br><span class="line">  AVAILABLE,</span><br><span class="line">  LEAVING</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><h2 id="分片分配"><a href="#分片分配" class="headerlink" title="分片分配"></a>分片分配</h2><p>分片的分配存储在etcd中。添加，删除或替换节点分片时，会为分配的每个分片分配目标状态。</p><p>要使写入对于给定副本显示为成功，它必须对该分片的所有已分配主机成功。这意味着如果存在给定的分片，其中主机被指定为LEAVING而另一个主机被分配为INITIALIZING，则给定的副本写入这两个主机必须看起来成功返回成功以写入该给定副本。然而，目前只有可用的分片计入一致性，在计算写入成功/错误时将LEAVING和INITIALIZING分片组合在一起的工作尚未完成，参见<a href="https://github.com/m3db/m3/issues/417" target="_blank" rel="noopener">问题417</a>。</p><p>当在INITIALIZING状态中发现分配新分片时，由节点本身自行引导分片，并在完成后通过调用集群管理API将状态转换为AVAILABLE。使用比较并以原子方式设置它将删除仍分配给先前拥有它的节点的LEAVING分片，并将新节点上的分片状态从INITIALIZING状态转换为AVAILABLE。</p><p>节点将不会开始为新分片提供读取，直到变为AVAILABLE，这意味着直到它们为这些分片提供了引导数据。</p><h2 id="群集操作"><a href="#群集操作" class="headerlink" title="群集操作"></a>群集操作</h2><h3 id="节点添加"><a href="#节点添加" class="headerlink" title="节点添加"></a>节点添加</h3><p>将节点添加到群集时，会为其分配分片，从而可以从现有节点中公平地减轻负载。 分配给新节点的分片将变为INITIALIZING，然后节点发现它们需要被引导，并将使用所有可用的副本开始引导数据。 将从现有节点中删除的分片标记为LEAVING。</p><h3 id="节点宕机"><a href="#节点宕机" class="headerlink" title="节点宕机"></a>节点宕机</h3><p>需要明确地从群集中取出节点。 如果节点发生故障并且不可用，则执行读取的客户端将从副本中为该节点拥有的分片范围提供错误。 在此期间，它将依赖来自其他副本的读取来继续不间断的操作。</p><h3 id="节点移除"><a href="#节点移除" class="headerlink" title="节点移除"></a>节点移除</h3><p>删除节点后，它拥有的分片将分配给群集中的现有节点。剩余的服务器发现它们现在拥有INITIALIZING的分片，需要进行自举，并将使用所有可用的副本开始引导数据。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;分片&quot;&gt;&lt;a href=&quot;#分片&quot; class=&quot;headerlink&quot; title=&quot;分片&quot;&gt;&lt;/a&gt;分片&lt;/h2&gt;&lt;p&gt;时间序列键被散列到一组固定的虚拟分片。然后将虚拟分片分配给物理节点。可以将M3DB配置为使用任何散列函数和配置数量的分片。默认情况下，&lt;a 
      
    
    </summary>
    
    
      <category term="m3db" scheme="http://blog.yapo.fun/tags/m3db/"/>
    
      <category term="时间序列数据库" scheme="http://blog.yapo.fun/tags/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>存储引擎概览</title>
    <link href="http://blog.yapo.fun/2019/05/16/m3/m3db/architecure/Storage-Engine-Overview/"/>
    <id>http://blog.yapo.fun/2019/05/16/m3/m3db/architecure/Storage-Engine-Overview/</id>
    <published>2019-05-16T06:29:00.000Z</published>
    <updated>2019-11-11T13:26:06.033Z</updated>
    
    <content type="html"><![CDATA[<p>M3DB是一个时间序列数据库，主要设计为可水平扩展并处理大量监视时间序列数据。</p><h2 id="时间序列压缩-M3TSZ"><a href="#时间序列压缩-M3TSZ" class="headerlink" title="时间序列压缩(M3TSZ)"></a>时间序列压缩(M3TSZ)</h2><p>M3DB作为时间序列数据库的最大优势之一（与使用更通用的水平可扩展分布式数据库，如Cassandra相反）是其压缩时间序列数据的能力，从而节省了大量内存和磁盘。 这种高压缩比是通过M3TSZ算法实现的，这是<a href="http://www.vldb.org/pvldb/vol8/p1816-teller.pdf" target="_blank" rel="noopener"><strong>Facebook的Gorilla论文</strong></a>中描述的流时间序列压缩算法的一种变体，但有一些小差别。</p><p>压缩比将根据工作负载和配置而有所不同，但我们发现使用M3TSZ，我们能够实现与Uber生产工作负载的<strong>1.45字节/数据点</strong>的压缩比。这比标准TSZ提高了40％，在相同条件下仅给出了2.42字节/数据点的压缩比。</p><h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><p>M3DB是一个具有持久存储的持久数据库，但最好通过其<strong>内存中对象布局和磁盘表示</strong>之间的边界来理解。</p><h2 id="内存布局"><a href="#内存布局" class="headerlink" title="内存布局"></a>内存布局</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">                ┌───────────────────────────────┐</span><br><span class="line">┌───────────────┤           Database            ├─────────────────┐</span><br><span class="line">│               └───────────────────────────────┘                 │</span><br><span class="line">│                                                                 │</span><br><span class="line">│                                                                 │</span><br><span class="line">│                                                                 │</span><br><span class="line">│               ┌───────────────────────────────┐                 │</span><br><span class="line">│     ┌─────────┤          Namespace 1          ├──────────┐      │</span><br><span class="line">│     │         └───────────────────────────────┘          │      │</span><br><span class="line">│     │                                                    │      │</span><br><span class="line">│     │                                                    │      │</span><br><span class="line">│     │                   ┌───────────┐                    │      │</span><br><span class="line">│     │    ┌──────────────┤  Shard 1  ├──────────────┐     │      │</span><br><span class="line">│     │    │              └───────────┘              │     │      │</span><br><span class="line">│     │    │                                         │     │      │</span><br><span class="line">│     │    │                                         │     │      │</span><br><span class="line">│     │    │              ┌───────────┐              │     │      │</span><br><span class="line">│     │    │   ┌──────────┤ Series 1  ├──────────┐   │     │      │</span><br><span class="line">│     │    │   │          └───────────┘          │   │     │      │</span><br><span class="line">│     │    │   │                                 │   │     │      │</span><br><span class="line">│     │    │   │                                 │   │     │      │</span><br><span class="line">│     │    │   │ ┌─────────────────────────────┐ │   │     │      │</span><br><span class="line">│     │    │   │ │      Block [2PM - 4PM]      │ │   │     │      │</span><br><span class="line">│     │    │   │ ├─────────────────────────────┤ │   │     │      │</span><br><span class="line">│     │    │   │ │      Block [4PM - 6PM]      │ │   │     │      │</span><br><span class="line">│     │    │   │ ├─────────────────────────────┤ │   │     │      │</span><br><span class="line">│     │    │   │ │       ┌────────────┐        │ │   │     │      │</span><br><span class="line">│     │    │   │ └───────┤   Blocks   ├────────┘ │   │     │      │</span><br><span class="line">│     │    │   │         └────────────┘          │   │     │      │</span><br><span class="line">│     │    │   │                                 │   │     │      │</span><br><span class="line">│     │    │   │                                 │   │     │      │</span><br><span class="line">│     │    │   │  ┌────────────────────────────┐ │   │     │      │</span><br><span class="line">│     │    │   │  │                            │ │   │     │      │</span><br><span class="line">│     │    │   │  │     Block [6PM - 8PM]      │ │   │     │      │</span><br><span class="line">│     │    │   │  │                            │ │   │     │      │</span><br><span class="line">│     │    │   │  ├────────────────────────────┤ │   │     │      │</span><br><span class="line">│     │    │   │  │ Active Buffers (encoders)  │ │   │     │      │</span><br><span class="line">│     │    │   │  └────────────────────────────┘ │   │     │      │</span><br><span class="line">│     │    │   │                                 │   │     │      │</span><br><span class="line">│     │    │   │                                 │   │     │      │</span><br><span class="line">│     │    │   └─────────────────────────────────┘   │     │      │</span><br><span class="line">│     │    │                                         │     │      │</span><br><span class="line">│     │    │                                         │     │      │</span><br><span class="line">│     │    │                                         │     │      │</span><br><span class="line">│     │    │                                         │     │      │</span><br><span class="line">│     │    └─────────────────────────────────────────┘     │      │</span><br><span class="line">│     │                                                    │      │</span><br><span class="line">│     │                                                    │      │</span><br><span class="line">│     └────────────────────────────────────────────────────┘      │</span><br><span class="line">│                                                                 │</span><br><span class="line">└─────────────────────────────────────────────────────────────────┘</span><br></pre></td></tr></table></figure><p>M3DB的内存部分是通过对象层次结构实现的：</p><ol><li><strong>每个M3DB进程只有一个<code>database</code></strong>。</li><li>数据库“拥有”许多名称空间，每个名称空间都有一个唯一的名称以及关于数据保留期和块大小的不同配置（我们将在后面详细讨论）。<strong>命名空间与其他数据库中的表类似</strong>。</li><li>命名空间拥有的分片(shard)。分片实际上与Cassandra中的“虚拟分片”相同，因为它们通过系列ID的简单散列提供时间序列数据的任意分布。</li><li>序列由分片拥有。当您想到“时间序列”数据时，通常会想到一个系列。例如:一段时间内数据中心中单个主机的CPU级别可以表示为id为“.system.cpu.utilization”的序列和（TIMESTAMP，CPU_LEVEL）形式的元组向量。换句话说，如果您渲染图形，则序列将表示该图形上的单个线条。请注意，前面的示例只是一个逻辑说明，并不代表M3DB实际存储数据的方式。</li><li><em>块属于一系列，是M3DB设计的核心</em>。块只是密封（不再可写）压缩时间序列数据流周围的较小包装器对象。压缩有一些注意事项，即您无法读取压缩块中的单个数据点。换句话说，<strong>为了读取单个数据点，您必须将整个块解压缩到您尝试读取的数据点</strong>。</li></ol><p>如果M3DB将所有内容保存在内存中（事实上，它的早期版本确实是这么做的），那么您可以从概念上将其视为由地图层次结构组成：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">database_obect      =&gt; map&lt;namepace_name, namespace_object&gt;</span><br><span class="line">namespace_object    =&gt; map&lt;shard_id, shard_object&gt;</span><br><span class="line">shard_object        =&gt; map&lt;series_id, series_object&gt;</span><br><span class="line">series_object       =&gt; map&lt;block_start_time, block_object&gt;</span><br><span class="line">series_object       =&gt; map&lt;block_start_time, active_buffers(encoders)&gt; (This map should only have one or two entries)</span><br></pre></td></tr></table></figure></p><h3 id="持久存储"><a href="#持久存储" class="headerlink" title="持久存储"></a>持久存储</h3><p>虽然内存数据库可能很有用（并且M3DB支持在仅内存模式下运行），但持久性需要某种形式的持久性。 换句话说，如果没有持久性策略，M3DB就不可能在不丢失所有数据的情况下重新启动（或从崩溃中恢复）。</p><p>此外，对于大量数据，将所有数据保存在内存中变得非常昂贵。对于监控工作负载尤其如此，这些工作负载通常遵循<strong>“一次写入，从不读取”</strong>模式，其中所存储的所有数据中只有不到百分之几被读取。 使用这种类型的工作负载时，如果可以将所有数据保存在磁盘上并在需要时检索，则将所有数据保存在内存中显得太浪费了。</p><p>与大多数其他数据库一样，M3DB采用双管齐下的持久存储方法，包括将<strong>commitlog（用于灾难恢复）与定期快照（用于高效检索）相结合</strong>：</p><ol><li>所有写入都持久保存到<a href="https://m3db.github.io/m3/m3db/architecture/commitlogs/" target="_blank" rel="noopener">commitlog</a>（commitlog可以配置为fsync每次写入，或者可选地批量一起写入，速度快得多，但在发生灾难性故障的情况下可能会丢失少量数据）。<strong>commitlog完全未压缩，仅在数据库关闭（有意或无意）的情况下恢复“未刷新”数据，并且永远不会用于满足读取请求。</strong></li><li>定期（基于配置的块大小）所有“活动”块被“密封”（标记为不可变）并作为“<a href="https://m3db.github.io/m3/m3db/architecture/storage/" target="_blank" rel="noopener">文件集</a>”文件刷入(flush)到磁盘。 这些文件是高度压缩的，可以通过其互补索引文件编入索引。查看刷入(flush)部分，了解有关<a href="https://m3db.github.io/m3/m3db/architecture/engine/#flushing" target="_blank" rel="noopener">刷入(flush)过程</a>背景的更多信息。</li></ol><p><strong>blocksize参数是需要针对特定工作负载进行调整的最重要变量</strong>。较小的块大小意味着更频繁的刷新，并且正在被主动压缩的数据的内存占用更少，但它也会降低压缩比，并且您的数据将占用磁盘上更多的空间。</p><p>如果数据库由于“刷入”（将文件集文件写入磁盘）之间的任何原因而停止，那么当节点启动备份时，需要通过读取提交日志或来自对等方的数据流来恢复这些写入 负责相同的分片（如果复制因子大于1）。</p><p>虽然<a href="https://m3db.github.io/m3/m3db/architecture/storage/" target="_blank" rel="noopener">文件集文件</a>旨在通过序列主键（ID）支持高效的数据检索，但是任何必须从磁盘检索数据的查询仍然存在沉重的成本，因为转到磁盘总是比访问主内存慢得多。<strong>为了弥补这一点，M3DB支持各种缓存策略，这些策略可以通过缓存内存中的数据来显着提高读取性能</strong>。</p><h2 id="写入路径"><a href="#写入路径" class="headerlink" title="写入路径"></a>写入路径</h2><p>我们现在有足够的M3DB架构上下文来讨论写入的生命周期。当M3DB客户端调用M3DB的嵌入式thrift服务器上的<a href="https://github.com/m3db/m3/blob/06d3ecc94d13cff67b82a791271816caa338dcab/src/dbnode/generated/thrift/rpc.thrift#L59" target="_blank" rel="noopener">writeBatchRaw</a>端点时，写入开始。写本身将包含以下信息：</p><ol><li>命名空间</li><li>系列ID（字节blob）</li><li>时间戳</li><li>value值本身</li></ol><p>M3DB将查询数据库对象以检查命名空间是否存在，如果存在，则它将散列序列ID以确定它属于哪个分片。如果接收write的节点拥有该分片，那么它将在分片对象中查找该序列。如果序列存在，那么它将查找序列的相应编码器并将数据点编码到<strong>压缩流</strong>中。如果编码器不存在（此系列的编码尚未作为此块的一部分发生），则将分配新的编码器，它将开始具有该数据点的压缩M3TSZ流。还有一些用于处理<strong>无序写入</strong>的特殊逻辑，在<a href="https://m3db.github.io/m3/m3db/architecture/engine/#merging-all-enoders" target="_blank" rel="noopener">合并所有编码器</a>部分中讨论。</p><p>同时，写入将附加到commitlog队列（并且取决于commitlog配置，立即fsync到磁盘或与其他写入一起批处理并立即刷新）。</p><p>写入将仅存在于此“活动缓冲区”和commitlog中，直到块结束并刷入到磁盘，此时写入将存在于文件集文件中，以便以后进行有效存储和检索，并且可以对commitlog条目进行垃圾回收。</p><p>注意：无论在单个节点中写入成功与否，客户端都将根据配置的<a href="https://m3db.github.io/m3/m3db/architecture/consistencylevels/" target="_blank" rel="noopener">一致性级别</a>向调用方返回成功或失败。</p><h2 id="读取路径"><a href="#读取路径" class="headerlink" title="读取路径"></a>读取路径</h2><p>当M3DB客户端调用M3DB嵌入式thrift服务器上的<a href="https://github.com/m3db/m3/blob/master/src/dbnode/generated/thrift/rpc.thrift" target="_blank" rel="noopener">FetchBatchResult</a>或<a href="https://github.com/m3db/m3/blob/master/src/dbnode/generated/thrift/rpc.thrift" target="_blank" rel="noopener">FetchBlocksRawResult</a>端点时，将开始读取。读取请求将包含以下信息：</p><ol><li>命名空间</li><li>序列ID（字节blob）</li><li>请求的时间段（开始和结束）</li></ol><p>M3DB将查询数据库对象以检查命名空间是否存在，如果存在，则<strong>它将散列系列ID以确定它属于哪个分片</strong>。如果接收读取的节点拥有该碎片，那么M3DB需要确定两件事：</p><ol><li>该系列是否存在？如果确实如此</li><li>数据是存在于“活动缓冲区”中（由编码器主动压缩），缓存在内存中，磁盘上还是三者的某种组合？</li></ol><p>确定系列是否存在很简单。M3DB在分片对象中查找该系列。如果存在，则系列存在。如果没有，则M3DB查询该分片/块启动组合的内存布隆过滤器，以确定该系列是否存在于磁盘上。</p><p>如果系列存在，那么对于请求跨越的每个块，M3DB需要合并来自活动缓冲区，内存高速缓存和文件集文件（磁盘）的数据。</p><p>让我们设想一个读取给定系列请求最后6个小时的数据，以及一个配置了2个小时的块大小的M3DB命名空间（即我们需要找到3个不同的块）。</p><p>如果当前时间是晚上8点，则所请求的块的位置可能如下所示：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[2PM - 4PM (FileSet file)]    - 已密封并刷入磁盘但未缓存</span><br><span class="line">[4PM - 6PM (In-memory cache)] - 已密封并刷入磁盘且缓存</span><br><span class="line">[6PM - 8PM (active buffer)]   - 未密封、未刷入存盘</span><br></pre></td></tr></table></figure></p><p>那么M3DB需要合并:</p><ol><li>来自活动缓冲区/编码器的尚未密封的块（位于Series对象内部查找内）<strong>[6PM-8PM]</strong></li><li>内存中缓存块(也位于Series对象内部查找内）<strong>[4PM-6PM]</strong></li><li>来自磁盘的块(从磁盘检索的块将根据当前的缓存策略进行缓存<strong>)[2PM-4PM]</strong></li></ol><p>从活动缓冲区和内存缓存中检索块很简单，数据已经存在于内存中，并且可以通过序列ID键入的哈希映射轻松访问。从磁盘检索块更复杂。从磁盘检索块的流程如下：</p><ol><li>查询内存中的bloom过滤器，以确定该系列是否存在于磁盘上。</li><li><strong>如果bloom过滤器返回存在，则二进制搜索内存中索引摘要以查找我们正在搜索的序列ID之前的最近索引条目。查看index_lookup.go文件以获取实现详细信息。</strong></li><li>跳转到我们在上一步中从二进制搜索中获得的索引文件中的偏移量，并开始向前扫描，直到我们识别出我们正在寻找的系列ID的索引条目，或者我们在索引文件中得到足够远以确认我们正在寻找的ID不存在（这是可能的，因为索引文件按ID排序）</li><li>跳转到我们在上一步中扫描索引文件获得的数据文件中的偏移量，并开始流式传输数据。</li></ol><p>一旦M3DB从内存/磁盘上各自的位置检索到三个块，它就会将所有数据传回客户端。<strong>客户端是否向调用者返回读取成功取决于配置的<a href="https://m3db.github.io/m3/m3db/architecture/consistencylevels/" target="_blank" rel="noopener">一致性级别</a>。</strong></p><p>注意：<strong>由于M3DB节点返回压缩块（M3DB客户端对它们进行解压缩），因此无法为给定块返回“部分结果”。 如果读取请求的任何部分跨越给定块，则该块的整体必须被传送回客户端。实际上，由于M3DB能够实现高压缩比，因此最终不会成为问题。</strong></p><h2 id="后台进程"><a href="#后台进程" class="headerlink" title="后台进程"></a>后台进程</h2><p>M3DB具有在正常操作期间在后台运行的各种进程。</p><h3 id="滴答"><a href="#滴答" class="headerlink" title="滴答"></a>滴答</h3><p>滴答进程在后台持续运行，负责各种任务：</p><ol><li>合并给定系列/块起始组合的所有编码器</li><li>从内存中删除过期/刷入的序列和块</li><li>从文件系统中清除过期数据（文件集/提交日志）</li></ol><h4 id="合并所有编码器"><a href="#合并所有编码器" class="headerlink" title="合并所有编码器"></a>合并所有编码器</h4><p>M3TSZ设计用于压缩时间序列数据，其中每个数据点的时间戳大于最后编码的数据点。 对于监视工作负载，这非常有效，因为每个后续数据点几乎总是在前一个数据点之后按时间顺序排列。 但是，现实世界的系统很乱，偶尔会收到无序写入。 发生这种情况时，M3DB将为无序数据点分配新的编码器。 在将数据刷新到磁盘之前需要合并多个编码器，但为了防止在刷新过程中出现大量内存峰值，我们会在后台不断合并乱序编码器。</p><h4 id="从内存中删除过期-刷入的序列和块"><a href="#从内存中删除过期-刷入的序列和块" class="headerlink" title="从内存中删除过期/刷入的序列和块"></a>从内存中删除过期/刷入的序列和块</h4><p>根据配置的缓存策略，内存中对象布局最终可能会引用已过期的系列或数据块（已超出保留期）或不再需要在内存中（由于数据被刷入）到磁盘或不再需要缓存）。后台滴答进程将识别这些结构并从内存中释放它们。</p><h3 id="刷入"><a href="#刷入" class="headerlink" title="刷入"></a>刷入</h3><p>正如<a href="https://m3db.github.io/m3/m3db/architecture/engine/#architecture" target="_blank" rel="noopener">架构部分</a>所讨论的那样，写入在内存中被主动缓冲/压缩，并且持续写入提交日志，但最终需要以<a href="https://m3db.github.io/m3/m3db/architecture/storage/" target="_blank" rel="noopener">文件集文件</a>的形式将数据刷入到磁盘，以便于高效存储和检索。</p><p>这是可配置的“blocksize”发挥作用的地方。块大小只是一段时间，它指示在“密封”（标记为不可变）并刷新到磁盘之前，在内存中压缩活动写入的时间（以流方式）。让我们使用两个小时的块大小作为例子。</p><p>如果blocksize设置为两个小时，则给定分片的所有序列的所有写入将一次缓冲在内存中两个小时。在两小时结束时，将生成所有文件集文件，写入磁盘，然后可以释放内存中的对象并替换为新块的新文件。旧对象将在后续滴答从内存中删除。</p><h2 id="警告-限制"><a href="#警告-限制" class="headerlink" title="警告/限制"></a>警告/限制</h2><ol><li>目前，M3DB不支持任意更新或删除。在可变块中支持时间序列数据的upsert，但是在时间序列数据移出可变窗口之后，它变得不可变。</li><li>M3DB不支持任意写入过去和未来。这对于监视工作负载通常很好，但对于传统的<a href="https://en.wikipedia.org/wiki/Online_transaction_processing" target="_blank" rel="noopener">OLTP</a>和<a href="https://en.wikipedia.org/wiki/Online_analytical_processing" target="_blank" rel="noopener">OLAP</a>工作负载可能会有问题。未来版本的M3DB将更好地支持具有任意时间戳的写入。</li><li>M3DB不支持使用双精度浮点数以外的值写入数据点。未来版本的M3DB将支持存储任意值。</li><li>M3DB不支持以无限期保留期存储数据，M3DB中的每个命名空间都需要具有保留策略，该策略指定将保留该命名空间中的数据的时间长度。虽然该值没有上限（Uber的生产数据库运行时保留期高达5年），但仍然需要并且一般来说M3DB针对具有明确定义的<a href="https://en.wikipedia.org/wiki/Time_to_live" target="_blank" rel="noopener">TTL</a>的工作负载进行了优化。</li><li>M3DB不支持后台数据修复或Cassandra式<a href="https://docs.datastax.com/en/cassandra/2.1/cassandra/operations/opsRepairNodesReadRepair.html" target="_blank" rel="noopener">读取修复</a>。未来版本的M3DB将支持作为持续运行的后台进程的数据自动修复。</li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;M3DB是一个时间序列数据库，主要设计为可水平扩展并处理大量监视时间序列数据。&lt;/p&gt;
&lt;h2 id=&quot;时间序列压缩-M3TSZ&quot;&gt;&lt;a href=&quot;#时间序列压缩-M3TSZ&quot; class=&quot;headerlink&quot; title=&quot;时间序列压缩(M3TSZ)&quot;&gt;&lt;/a&gt;时间
      
    
    </summary>
    
    
      <category term="m3db" scheme="http://blog.yapo.fun/tags/m3db/"/>
    
      <category term="时间序列数据库" scheme="http://blog.yapo.fun/tags/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>M3DB, 一个分布式时间序列数据库</title>
    <link href="http://blog.yapo.fun/2019/05/16/m3/m3db/introduction/"/>
    <id>http://blog.yapo.fun/2019/05/16/m3/m3db/introduction/</id>
    <published>2019-05-16T05:53:00.000Z</published>
    <updated>2019-11-11T13:26:06.033Z</updated>
    
    <content type="html"><![CDATA[<h2 id="关于"><a href="#关于" class="headerlink" title="关于"></a>关于</h2><p>受<a href="http://www.vldb.org/pvldb/vol8/p1816-teller.pdf" target="_blank" rel="noopener">Gorilla</a>和<a href="http://cassandra.apache.org/" target="_blank" rel="noopener">Cassandra</a>启发的M3DB是Uber Technologies公开发布的分布式时间序列数据库。它可用于存储长时间保留的实时指标。</p><p>以下是该项目的一些属性：</p><ul><li>分布式时间序列存储，单个节点使用WAL提交日志并独立地保留每个分片的时间窗口</li><li>集群管理建立在etcd之上</li><li>内置的同步复制，具有可配置的持久性和读取一致性（一个，多数，所有等）</li><li>受大Gorilla TSZ压缩启发的M3TSZ float64压缩，可配置为无损或有损</li><li>任意时间精度可配置为秒到纳秒的精度，能够在任何写入时切换精度</li><li>可配置的乱序写入，目前仅限于配置的时间窗口的块大小</li></ul><h2 id="现有限制"><a href="#现有限制" class="headerlink" title="现有限制"></a>现有限制</h2><p>由于项目需求的性质，主要是为了降低摄取和存储数十亿个时间序列的成本并提供快速可扩展的读取，<strong>目前有一些限制使M3DB不适合用作通用时间序列 数据库</strong>。</p><p>该项目旨在尽可能避免压缩，目前M3DB执行的唯一压缩是在可变压缩时间序列窗口的内存中（默认配置为2小时）。 因此，乱序写入限于单个压缩时间序列窗口的大小。 因此，目前无法回填大量数据。</p><p>该项目还针对float64值的存储和检索进行了优化，因此无法将其用作任意数据结构的通用时间序列数据库。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;关于&quot;&gt;&lt;a href=&quot;#关于&quot; class=&quot;headerlink&quot; title=&quot;关于&quot;&gt;&lt;/a&gt;关于&lt;/h2&gt;&lt;p&gt;受&lt;a href=&quot;http://www.vldb.org/pvldb/vol8/p1816-teller.pdf&quot; target=&quot;_bl
      
    
    </summary>
    
    
      <category term="m3db" scheme="http://blog.yapo.fun/tags/m3db/"/>
    
  </entry>
  
  <entry>
    <title>m3db架构概览</title>
    <link href="http://blog.yapo.fun/2019/05/16/m3/m3db/architecure/overview/"/>
    <id>http://blog.yapo.fun/2019/05/16/m3/m3db/architecure/overview/</id>
    <published>2019-05-16T05:53:00.000Z</published>
    <updated>2019-11-11T13:26:06.033Z</updated>
    
    <content type="html"><![CDATA[<h2 id="概览"><a href="#概览" class="headerlink" title="概览"></a>概览</h2><p>M3DB完全用Go编写，没有任何必需的依赖项。对于较大的部署，可以使用etcd集群来管理M3DB集群成员资格和拓扑定义。</p><h2 id="高水平目标"><a href="#高水平目标" class="headerlink" title="高水平目标"></a>高水平目标</h2><p>该项目的一些高水平目标定义为：</p><ul><li><p><strong>监控支持</strong>：M3DB主要用于收集大量监控时间序列数据，以水平可扩展方式分配存储，并最有效地利用硬件。 因此，不经常读取的时间序列不会保留在内存中。</p></li><li><p><strong>高度可配置</strong>：提供高级别的配置，以支持各种用例和运行时环境。</p></li><li><p><strong>持久性</strong>：为存储时间序列数据的写入和读取方提供可变持久性保证，使更多种类的应用程序可以使用M3DB。这就是为什么复制主要是同步的，并提供可配置的一致性级别，以实现<strong>一致的写入和读取</strong>。必须能够使用具有强大保证的M3DB，即数据被复制到<strong>法定数量</strong>的节点，并且如果需要，数据是持久的。</p></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;概览&quot;&gt;&lt;a href=&quot;#概览&quot; class=&quot;headerlink&quot; title=&quot;概览&quot;&gt;&lt;/a&gt;概览&lt;/h2&gt;&lt;p&gt;M3DB完全用Go编写，没有任何必需的依赖项。对于较大的部署，可以使用etcd集群来管理M3DB集群成员资格和拓扑定义。&lt;/p&gt;
&lt;h2 i
      
    
    </summary>
    
    
      <category term="m3db" scheme="http://blog.yapo.fun/tags/m3db/"/>
    
      <category term="时间序列数据库" scheme="http://blog.yapo.fun/tags/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>概览-媒体</title>
    <link href="http://blog.yapo.fun/2019/05/16/m3/overview/media/"/>
    <id>http://blog.yapo.fun/2019/05/16/m3/overview/media/</id>
    <published>2019-05-16T03:26:00.000Z</published>
    <updated>2019-11-11T13:26:06.033Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Media"><a href="#Media" class="headerlink" title="Media"></a>Media</h1><h2 id="Blogs"><a href="#Blogs" class="headerlink" title="Blogs"></a>Blogs</h2><ul><li><p><a href="https://eng.uber.com/m3" target="_blank" rel="noopener">M3: Uber’s Open Source, Large-scale Metrics Platform for Prometheus</a> By Rob Skillington - Aug 7, 2018.</p></li><li><p><a href="https://eng.uber.com/billion-data-point-challenge" target="_blank" rel="noopener">Building a Query Engine for High Cardinality Time Series Data</a> By Nikunj Aggarwal and Ben Raskin - Dec 10, 2018.</p></li></ul><h2 id="Recorded-Talks"><a href="#Recorded-Talks" class="headerlink" title="Recorded Talks"></a>Recorded Talks</h2><ul><li><p><a href="https://www.youtube.com/watch?v=aDFm5KaTaOk" target="_blank" rel="noopener">KubeCon Seattle 2018 Keynote: Smooth Operator♪: Large Scale Automated Storage with Kubernetes</a> By Celina Ward &amp; Matt Schallert - Dec 13, 2018.</p></li><li><p><a href="https://www.youtube.com/watch?v=mrq-TBXpztU" target="_blank" rel="noopener">Learnings, patterns and Uber’s metrics platform M3, open sourced as a Prometheus long term storage backend</a> By Rob Skillington - Nov 5, 2018. <a href="https://www.slideshare.net/NETWAYS/osmc-2018-learnings-patterns-and-ubers-metrics-platform-m3-open-sourced-as-a-prometheus-long-term-storage-backend-by-rob-skillington" target="_blank" rel="noopener">Slides</a></p></li><li><p><a href="https://www.youtube.com/watch?v=W9duNO2dauc" target="_blank" rel="noopener">Adventures in building a high-volume Time-Series Database</a> By Richard Artoul &amp; Prateek Rungta - Nov 4, 2018.</p></li><li><p><a href="https://www.youtube.com/watch?v=_L5RjJ7MVv4&amp;t=1675" target="_blank" rel="noopener">PromCon 2018 Lightning Talk: M3 with Prometheus</a> by Nikunj Aggarwal - Aug 9, 2018.</p></li><li><p><a href="https://youtube.com/watch?v=3pTG_N8yGSU" target="_blank" rel="noopener">PromCon 2018 Panel Discussion: Prometheus Long-Term Storage Approaches</a> including highlights of the M3 stack by Nikunj Aggarwal - Aug 9, 2018.</p></li><li><p><a href="https://vimeo.com/274821002" target="_blank" rel="noopener">Putting billions of time series to work at Uber with autonomous monitoring</a> By Prateek Rungta - Jun 6, 2018. <a href="http://bit.ly/m3db-monitorama2018" target="_blank" rel="noopener">Slides</a></p></li><li><p><a href="https://fosdem.org/2019/schedule/event/m3_and_a_new_age_of_metrics_and_monitoring_in_an_increasingly_complex_world/" target="_blank" rel="noopener">M3 and a new age of metrics and monitoring in an increasingly complex world</a> By Rob Skillington - Feb 3, 2019.</p></li><li><p><a href="https://www.youtube.com/watch?v=Ti5z1v-3jWA" target="_blank" rel="noopener">Building Operators at Uber</a> By Matt Schallert &amp; Paul Schooss - Mar 11,<br>2019.</p></li></ul><h2 id="Upcoming-Talks"><a href="#Upcoming-Talks" class="headerlink" title="Upcoming Talks"></a>Upcoming Talks</h2><ul><li><a href="https://kccnceu19.sched.com/event/MPbX/m3-and-prometheus-monitoring-at-planet-scale-for-everyone-rob-skillington-uber" target="_blank" rel="noopener">M3 and Prometheus, Monitoring at Planet Scale for Everyone</a> By Rob Skillington - May 22, 2019</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;Media&quot;&gt;&lt;a href=&quot;#Media&quot; class=&quot;headerlink&quot; title=&quot;Media&quot;&gt;&lt;/a&gt;Media&lt;/h1&gt;&lt;h2 id=&quot;Blogs&quot;&gt;&lt;a href=&quot;#Blogs&quot; class=&quot;headerlink&quot; title=&quot;Blo
      
    
    </summary>
    
    
      <category term="m3db" scheme="http://blog.yapo.fun/tags/m3db/"/>
    
      <category term="时间序列数据库" scheme="http://blog.yapo.fun/tags/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>概览-动机</title>
    <link href="http://blog.yapo.fun/2019/05/16/m3/overview/motivation/"/>
    <id>http://blog.yapo.fun/2019/05/16/m3/overview/motivation/</id>
    <published>2019-05-16T03:25:25.000Z</published>
    <updated>2019-11-11T13:26:06.033Z</updated>
    
    <content type="html"><![CDATA[<p>我们决定将M3平台作为Prometheus和Graphite的可扩展远程存储后端开源，以便其他人可以尝试重用我们的工作并避免构建另一个可扩展的度量平台。正如Prometheus的文档所述，它在可扩展性和持久性方面受到单个节点的限制。 M3平台旨在为Prometheus，Graphite和其他标准指标模式提供交钥匙，可扩展且可配置的多租户存储。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;我们决定将M3平台作为Prometheus和Graphite的可扩展远程存储后端开源，以便其他人可以尝试重用我们的工作并避免构建另一个可扩展的度量平台。正如Prometheus的文档所述，它在可扩展性和持久性方面受到单个节点的限制。 M3平台旨在为Prometheus，Gr
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>概览-组件</title>
    <link href="http://blog.yapo.fun/2019/05/16/m3/overview/components/"/>
    <id>http://blog.yapo.fun/2019/05/16/m3/overview/components/</id>
    <published>2019-05-16T03:24:00.000Z</published>
    <updated>2019-11-11T13:26:06.033Z</updated>
    
    <content type="html"><![CDATA[<h2 id="M3协调器"><a href="#M3协调器" class="headerlink" title="M3协调器"></a>M3协调器</h2><p>M3 Coordinator是一种服务，用于协调上游系统（如Prometheus和M3DB）之间的读写操作。 它是用户可以部署以访问M3DB的优势的桥梁，例如长期存储和与其他监控系统（如Prometheus）的多DC设置。 有关Prometheus长期存储的更多信息，请参阅<a href="https://schd.ws/hosted_files/cloudnativeeu2017/73/Integrating%20Long-Term%20Storage%20with%20Prometheus%20-%20CloudNativeCon%20Berlin%2C%20March%2030%2C%202017.pdf" target="_blank" rel="noopener">此演示文稿</a>。 </p><h2 id="M3DB"><a href="#M3DB" class="headerlink" title="M3DB"></a>M3DB</h2><p>M3DB是一个分布式时间序列数据库，提供可扩展存储和时间序列的倒排索引。它经过优化，具有成本效益和可靠的实时和长期保留指标存储和索引。有关更多详细信息，请参阅<a href="https://m3db.github.io/m3db/" target="_blank" rel="noopener">M3DB文档</a>。</p><h2 id="M3-Query"><a href="#M3-Query" class="headerlink" title="M3 Query"></a>M3 Query</h2><p>M3 Query是一种服务，它包含一个分布式查询引擎，用于查询实时和历史指标，支持多种不同的查询语言。 它旨在支持低延迟实时查询和可能需要更长时间执行的查询，聚合更大的数据集，以用于分析用例。 有关更多详细信息，请参阅<a href="https://m3db.github.io/query_engine/" target="_blank" rel="noopener">查询引擎文档</a>。</p><h2 id="M3聚合器"><a href="#M3聚合器" class="headerlink" title="M3聚合器"></a>M3聚合器</h2><p>M3 Aggregator是一种作为专用度量聚合器运行的服务，它基于存储在etcd中的动态规则提供基于流的降采样。 它使用领导者选举和聚合窗口跟踪，利用etcd来管理这种状态，从而可靠地发出至少一次的聚合，以便将降采样的指标用于长期存储。 这提供了成本有效且可靠的降采样和汇总指标。 这些功能也存在于M3协调器中，但是专用聚合器是分片和复制的，而M3协调器则不需要谨慎部署和以高可用性方式运行。 还有一些工作要使用户更容易访问聚合器，而无需他们编写自己的兼容生产者和消费者。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;M3协调器&quot;&gt;&lt;a href=&quot;#M3协调器&quot; class=&quot;headerlink&quot; title=&quot;M3协调器&quot;&gt;&lt;/a&gt;M3协调器&lt;/h2&gt;&lt;p&gt;M3 Coordinator是一种服务，用于协调上游系统（如Prometheus和M3DB）之间的读写操作。 它是用
      
    
    </summary>
    
    
      <category term="m3db" scheme="http://blog.yapo.fun/tags/m3db/"/>
    
      <category term="时间序列数据库" scheme="http://blog.yapo.fun/tags/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>关于m3</title>
    <link href="http://blog.yapo.fun/2019/05/16/m3/m3-about/"/>
    <id>http://blog.yapo.fun/2019/05/16/m3/m3-about/</id>
    <published>2019-05-16T03:22:00.000Z</published>
    <updated>2019-11-11T13:26:06.033Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://m3db.github.io/m3/" target="_blank" rel="noopener">原文</a></p><h2 id="关于"><a href="#关于" class="headerlink" title="关于"></a>关于</h2><p>在使用开源指标解决方案并大规模发现问题（例如可靠性，成本和操作复杂性）之后，M3从头开始创建，为Uber提供本地分布式时间序列数据库，高度动态且高性能 聚合服务，查询引擎和其他支持基础设施。</p><h2 id="重要功能"><a href="#重要功能" class="headerlink" title="重要功能"></a>重要功能</h2><p>M3具有多种功能，作为分立组件提供，使其成为大规模时间序列数据的理想平台：</p><ul><li>分布式时间序列数据库M3DB，为时间序列数据和倒排索引提供可扩展存储。</li><li>一个边车进程，M3Coordinator，允许M3DB作为普罗米修斯的长期存储。</li><li>一个分布式查询引擎，M3Query，支持PromQL和Graphite（M3QL即将推出）。</li><li>聚合层M3Aggregator，作为专用度量聚合器/降采样器运行，允许以不同分辨率的各种保留期限存储度量。</li></ul><h2 id="开始"><a href="#开始" class="headerlink" title="开始"></a>开始</h2><p>注意：在生产中运行之前，请务必阅读我们的<a href="https://m3db.github.io/m3/operational_guide/index.md" target="_blank" rel="noopener">操作指南</a>！</p><p>开始使用M3就像遵循其中一个操作指南,很简单:</p><ul><li><a href="https://m3db.github.io/m3/how_to/single_node/" target="_blank" rel="noopener">单个M3DB节点部署</a></li><li><a href="https://m3db.github.io/m3/how_to/cluster_hard_way/" target="_blank" rel="noopener">集群M3DB部署</a></li><li><a href="https://m3db.github.io/m3/how_to/kubernetes/" target="_blank" rel="noopener">Kubernetes上的M3DB</a></li><li><a href="https://m3db.github.io/m3/how_to/query/" target="_blank" rel="noopener">部署上的孤立M3Query</a></li></ul><h2 id="技术支持"><a href="#技术支持" class="headerlink" title="技术支持"></a>技术支持</h2><p>如需支持任何问题，有关M3或其操作的问题，或留下任何评论，可以通过多种方式联系团队：</p><ul><li><a href="https://gitter.im/m3db/Lobby" target="_blank" rel="noopener">Gitter</a></li><li><a href="https://groups.google.com/forum/#!forum/m3db" target="_blank" rel="noopener">Email</a></li><li><a href="https://github.com/m3db/m3/issues" target="_blank" rel="noopener">Github issues</a></li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;a href=&quot;https://m3db.github.io/m3/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;关于&quot;&gt;&lt;a href=&quot;#关于&quot; class=&quot;headerlink&quot; title=&quot;关于&quot;&gt;&lt;/
      
    
    </summary>
    
    
      <category term="m3db" scheme="http://blog.yapo.fun/tags/m3db/"/>
    
      <category term="时间序列数据库" scheme="http://blog.yapo.fun/tags/%E6%97%B6%E9%97%B4%E5%BA%8F%E5%88%97%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
  </entry>
  
  <entry>
    <title>从源码编译golang 1.12</title>
    <link href="http://blog.yapo.fun/2019/04/13/golang/golang-compile-from-source-code/"/>
    <id>http://blog.yapo.fun/2019/04/13/golang/golang-compile-from-source-code/</id>
    <published>2019-04-12T16:39:00.000Z</published>
    <updated>2019-11-11T13:26:06.033Z</updated>
    
    <content type="html"><![CDATA[<ol><li><p>下载源码</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ mkdir studygo &amp;&amp; <span class="built_in">cd</span> studygo</span><br><span class="line">$ git <span class="built_in">clone</span> https://github.com/golang/go.git</span><br></pre></td></tr></table></figure></li><li><p>切换到1.4版本(需要先生成1.4版本的go，然后用1.4版本的去编译高版本的)</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> go</span><br><span class="line">$ git checkout release-branch.go1.4</span><br><span class="line">$ <span class="built_in">cd</span> ..;cp -r go go1.4</span><br><span class="line">$ <span class="built_in">cd</span> go/src</span><br><span class="line">$ ./make.bash</span><br><span class="line">---</span><br><span class="line">Installed Go <span class="keyword">for</span> linux/amd64 <span class="keyword">in</span> /home/arthur/gostudy/go1.4</span><br><span class="line">Installed commands <span class="keyword">in</span> /home/arthur/gostudy/go1.4/bin</span><br></pre></td></tr></table></figure></li><li><p>设置环境变量GOROOT_BOOTSTRAP，并编译go1.12.4</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">export</span> GOROOT_BOOTSTRAP=<span class="variable">$HOME</span>/studygo/go1.4</span><br><span class="line">$ git checkout release-branch.go1.12</span><br><span class="line">$ <span class="built_in">cd</span> ..;cp -r go go1.2</span><br><span class="line">$ <span class="built_in">cd</span> go1.2/src</span><br><span class="line">$ ./make.bash</span><br><span class="line">Building Go cmd/dist using /home/arthur/gostudy/go1.4.</span><br><span class="line">Building Go toolchain1 using /home/arthur/gostudy/go1.4.</span><br><span class="line">Building Go bootstrap cmd/go (go_bootstrap) using Go toolchain1.</span><br><span class="line">Building Go toolchain2 using go_bootstrap and Go toolchain1.</span><br><span class="line">Building Go toolchain3 using go_bootstrap and Go toolchain2.</span><br><span class="line">Building packages and commands <span class="keyword">for</span> linux/amd64.</span><br><span class="line">---</span><br><span class="line">Installed Go <span class="keyword">for</span> linux/amd64 <span class="keyword">in</span> /home/arthur/gostudy/go1.12</span><br><span class="line">Installed commands <span class="keyword">in</span> /home/arthur/gostudy/go1.12/bin</span><br></pre></td></tr></table></figure></li><li><p>可通过<code>go</code>命令验证</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ /home/arthur/gostudy/go1.12/bin/go version</span><br><span class="line">go version go1.12.4 linux/amd64</span><br></pre></td></tr></table></figure></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;ol&gt;
&lt;li&gt;&lt;p&gt;下载源码&lt;/p&gt;
&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/
      
    
    </summary>
    
      <category term="golang" scheme="http://blog.yapo.fun/categories/golang/"/>
    
    
      <category term="golang" scheme="http://blog.yapo.fun/tags/golang/"/>
    
  </entry>
  
  <entry>
    <title>prometheus-alerting-alertmanager</title>
    <link href="http://blog.yapo.fun/2019/04/09/prometheus-alerting-alertmanager/"/>
    <id>http://blog.yapo.fun/2019/04/09/prometheus-alerting-alertmanager/</id>
    <published>2019-04-09T07:10:00.000Z</published>
    <updated>2019-11-11T13:26:06.037Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://prometheus.io/docs/alerting/alertmanager/" target="_blank" rel="noopener">原文</a></p><p>Alertmanager处理客户端应用程序（如Prometheus服务器）发送的警报。它负责对它们进行重复数据删除，分组和路由，以及正确的接收器集成，例如电子邮件，PagerDuty或OpsGenie。它还负责警报的静音(silencing)和抑制(inhibition)。</p><p>以下描述了Alertmanager实现的核心概念。请参阅<a href="https://prometheus.io/docs/alerting/configuration" target="_blank" rel="noopener">配置文档</a>以了解如何更详细地使用它们。</p><h2 id="分组-Grouping"><a href="#分组-Grouping" class="headerlink" title="分组(Grouping)"></a>分组(Grouping)</h2><p>分组将类似性质的警报分类为单个通知。在许多系统一次性失败并且数百到数千个警报可能同时发生的较大中断(outage)期间，这尤其有用。</p><p><code>示例</code>：发生网络分区时，群集中正在运行数十或数百个服务实例。一半的服务实例无法再访问数据库。Prometheus中的警报规则配置为在每个服务实例无法与数据库通信时发送警报。结果，数百个警报被发送到Alertmanager。</p><p>作为用户，人们只想获得单个页面，同时仍能够确切地看到哪些服务实例受到影响。因此，可以将Alertmanager配置为按集群和alertname对警报进行分组，以便发送单个紧凑通知。</p><p>通过配置文件中的路由树配置警报的分组，分组通知的定时以及这些通知的接收器。</p><h2 id="告警抑制-Inhibition"><a href="#告警抑制-Inhibition" class="headerlink" title="告警抑制(Inhibition)"></a>告警抑制(Inhibition)</h2><p>如果某些其他警报已经触发，则<code>告警抑制</code>是抑制某些警报的通知的概念。</p><p><code>示例</code>：正在触发警报，通知无法访问整个集群。Alertmanager可以配置为在该特定警报触发时将与该集群有关的所有其他警报静音。这可以防止发送与实际问题无关的数百或数千个触发警报。</p><p><code>告警抑制通过Alertmanager的配置文件配置。</code></p><h2 id="静音-Silences"><a href="#静音-Silences" class="headerlink" title="静音(Silences)"></a>静音(Silences)</h2><p>静音(Siliences)是在给定时间内简单地静音警报(mute alerts)的简单方法。基于匹配器配置静音，就像路由树一样。检查传入警报是否与活动静音的相等或匹配正则表达式。如果符合，则不会发送该警报的通知。</p><p><code>在Alertmanager的Web界面中配置静音。</code></p><h2 id="客户行为"><a href="#客户行为" class="headerlink" title="客户行为"></a>客户行为</h2><p>Alertmanager对其客户的行为有<a href="https://prometheus.io/docs/alerting/clients" target="_blank" rel="noopener">特殊要求</a>。这些仅适用于不使用Prometheus发送警报的高级用例。</p><h2 id="高可用性"><a href="#高可用性" class="headerlink" title="高可用性"></a>高可用性</h2><p>Alertmanager支持配置以创建用于高可用性的集群。可以使用<a href="https://github.com/prometheus/alertmanager#high-availability" target="_blank" rel="noopener"><code>--cluster- *</code></a>标志进行配置。</p><p>不要在Prometheus和它的Alertmanagers之间加载平衡流量，而是将Prometheus指向所有Alertmanagers的列表。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;a href=&quot;https://prometheus.io/docs/alerting/alertmanager/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Alertmanager处理客户端应用程序（如Prometheu
      
    
    </summary>
    
      <category term="监控" scheme="http://blog.yapo.fun/categories/%E7%9B%91%E6%8E%A7/"/>
    
    
      <category term="prometheus" scheme="http://blog.yapo.fun/tags/prometheus/"/>
    
      <category term="监控" scheme="http://blog.yapo.fun/tags/%E7%9B%91%E6%8E%A7/"/>
    
  </entry>
  
  <entry>
    <title>prometheus-alerting-alertmanager</title>
    <link href="http://blog.yapo.fun/2019/04/09/prometheus/prometheus-alerting-alertmanager/"/>
    <id>http://blog.yapo.fun/2019/04/09/prometheus/prometheus-alerting-alertmanager/</id>
    <published>2019-04-09T07:10:00.000Z</published>
    <updated>2019-11-11T13:26:06.037Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://prometheus.io/docs/alerting/alertmanager/" target="_blank" rel="noopener">原文</a></p><p>Alertmanager处理客户端应用程序（如Prometheus服务器）发送的警报。它负责对它们进行重复数据删除，分组和路由，以及正确的接收器集成，例如电子邮件，PagerDuty或OpsGenie。它还负责警报的静音(silencing)和抑制(inhibition)。</p><p>以下描述了Alertmanager实现的核心概念。请参阅<a href="https://prometheus.io/docs/alerting/configuration" target="_blank" rel="noopener">配置文档</a>以了解如何更详细地使用它们。</p><h2 id="分组-Grouping"><a href="#分组-Grouping" class="headerlink" title="分组(Grouping)"></a>分组(Grouping)</h2><p>分组将类似性质的警报分类为单个通知。在许多系统一次性失败并且数百到数千个警报可能同时发生的较大中断(outage)期间，这尤其有用。</p><p><code>示例</code>：发生网络分区时，群集中正在运行数十或数百个服务实例。一半的服务实例无法再访问数据库。Prometheus中的警报规则配置为在每个服务实例无法与数据库通信时发送警报。结果，数百个警报被发送到Alertmanager。</p><p>作为用户，人们只想获得单个页面，同时仍能够确切地看到哪些服务实例受到影响。因此，可以将Alertmanager配置为按集群和alertname对警报进行分组，以便发送单个紧凑通知。</p><p>通过配置文件中的路由树配置警报的分组，分组通知的定时以及这些通知的接收器。</p><h2 id="告警抑制-Inhibition"><a href="#告警抑制-Inhibition" class="headerlink" title="告警抑制(Inhibition)"></a>告警抑制(Inhibition)</h2><p>如果某些其他警报已经触发，则<code>告警抑制</code>是抑制某些警报的通知的概念。</p><p><code>示例</code>：正在触发警报，通知无法访问整个集群。Alertmanager可以配置为在该特定警报触发时将与该集群有关的所有其他警报静音。这可以防止发送与实际问题无关的数百或数千个触发警报。</p><p><code>告警抑制通过Alertmanager的配置文件配置。</code></p><h2 id="静音-Silences"><a href="#静音-Silences" class="headerlink" title="静音(Silences)"></a>静音(Silences)</h2><p>静音(Siliences)是在给定时间内简单地静音警报(mute alerts)的简单方法。基于匹配器配置静音，就像路由树一样。检查传入警报是否与活动静音的相等或匹配正则表达式。如果符合，则不会发送该警报的通知。</p><p><code>在Alertmanager的Web界面中配置静音。</code></p><h2 id="客户行为"><a href="#客户行为" class="headerlink" title="客户行为"></a>客户行为</h2><p>Alertmanager对其客户的行为有<a href="https://prometheus.io/docs/alerting/clients" target="_blank" rel="noopener">特殊要求</a>。这些仅适用于不使用Prometheus发送警报的高级用例。</p><h2 id="高可用性"><a href="#高可用性" class="headerlink" title="高可用性"></a>高可用性</h2><p>Alertmanager支持配置以创建用于高可用性的集群。可以使用<a href="https://github.com/prometheus/alertmanager#high-availability" target="_blank" rel="noopener"><code>--cluster- *</code></a>标志进行配置。</p><p>不要在Prometheus和它的Alertmanagers之间加载平衡流量，而是将Prometheus指向所有Alertmanagers的列表。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;&lt;a href=&quot;https://prometheus.io/docs/alerting/alertmanager/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;原文&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Alertmanager处理客户端应用程序（如Prometheu
      
    
    </summary>
    
      <category term="监控" scheme="http://blog.yapo.fun/categories/%E7%9B%91%E6%8E%A7/"/>
    
    
      <category term="prometheus" scheme="http://blog.yapo.fun/tags/prometheus/"/>
    
      <category term="监控" scheme="http://blog.yapo.fun/tags/%E7%9B%91%E6%8E%A7/"/>
    
  </entry>
  
</feed>
